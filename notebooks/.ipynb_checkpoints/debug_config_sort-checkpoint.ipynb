{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a080960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_pretrained_model' from 'utils.checkpoint' (/raid6/ebihara/python/SPRTproject/UrgingMAUS/utils/checkpoint.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_sdre_imgs, log_training_results, TensorboardLogger\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhyperparameter_tuning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_optuna, suggest_parameters_optuna, report_to_pruner\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m checkpoint_logger, update_and_save_result, \\\n\u001b[1;32m     12\u001b[0m                              initialize_objectives, finalize_objectives, load_pretrained_model\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SDREData, get_sequential_data \n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtemporal_integrators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_pretrained_model' from 'utils.checkpoint' (/raid6/ebihara/python/SPRTproject/UrgingMAUS/utils/checkpoint.py)"
     ]
    }
   ],
   "source": [
    "import datetime, sys, os, time, pdb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "import tensorflow as tf\n",
    "sys.path.append('/raid6/ebihara/python/SPRTproject/UrgingMAUS')\n",
    "from config.config import config\n",
    "from utils.misc import set_gpu_devices, fix_random_seed\n",
    "from utils.logging import save_sdre_imgs, log_training_results, TensorboardLogger\n",
    "from utils.hyperparameter_tuning import run_optuna, suggest_parameters_optuna, report_to_pruner\n",
    "from utils.checkpoint import checkpoint_logger, update_and_save_result, \\\n",
    "                             initialize_objectives, finalize_objectives, load_pretrained_model\n",
    "from datasets.data_processing import SDREData, get_sequential_data \n",
    "from models.temporal_integrators import get_model\n",
    "from models.optimizers import get_optimizer\n",
    "from models.losses import get_gradient_tandemaus\n",
    "from utils.performance_metrics import llr_sequential_confmx, seqconfmx_to_metrics,\\\n",
    "                                calc_llr_abserr, average_dicts\n",
    "[print(k) for k in config.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "043ebccc",
   "metadata": {},
   "outputs": [],
   "source": [
    " def sort_config(config):\n",
    "    def calc_key_similarity(key):\n",
    "#         if key.startswith('LIST_'):\n",
    "#             return 0\n",
    "        key = key.replace('LIST_', '') if key.startswith('LIST_') else key\n",
    "        key_words = key.split('_')\n",
    "        key_score = 0\n",
    "        if 'activation' in key_words:\n",
    "            key_score += 1\n",
    "        if 'loss' in key_words:\n",
    "            key_score += 2\n",
    "        if 'encoding' in key_words:\n",
    "            key_score += 3\n",
    "        if 'version' in key_words:\n",
    "            key_score += 4\n",
    "        if  'if' in key_words or 'flag' in key_words:\n",
    "            key_score += 5\n",
    "        return key_score\n",
    "    def sort_nested_config(config):\n",
    "        if not isinstance(config, dict):\n",
    "            return config\n",
    "        sorted_keys = sorted(config.keys(), key=lambda k: (calc_key_similarity(k), k))\n",
    "        return {key: sort_nested_config(config[key]) for key in sorted_keys}\n",
    "    \n",
    "    return sort_nested_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b16d02c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERBOSE | ACTIVATION\n",
      "CONFIG_PATH | ALPHA\n",
      "IF_SEED | AUCLOSS_BURNIN\n",
      "SEED | AUCLOSS_VERSION\n",
      "GPU | BATCH_SIZE\n",
      "ROOT_DIR | BETA\n",
      "PROJECT_NAME | COMMENT\n",
      "NAME_DATASET | CONFIG_PATH\n",
      "ROOT_TBLOGS | DROPOUT\n",
      "ROOT_DBLOGS | EXP_PHASE\n",
      "ROOT_CKPTLOGS | ACTIVATION_FC\n",
      "ROOT_IMGLOGS | FEAT_DIMS\n",
      "PATH_RESUME | FF_DIM\n",
      "SUBPROJECT_NAME | FLAG_MULT\n",
      "COMMENT | GPU\n",
      "SAVE_FIGURE | GT_LLR_PATH\n",
      "X_PATH | HEAD_SIZE\n",
      "Y_PATH | IF_ADAPTIVE_LOSS\n",
      "GT_LLR_PATH | IF_NORMALIZE\n",
      "NUM_TRAIN | IF_POSITIONAL_ENCODING\n",
      "NUM_VAL | IF_RESUME\n",
      "NUM_TEST | IF_SEED\n",
      "NUM_CLASSES | IF_TRAINABLE_ENCODING\n",
      "FEAT_DIMS | IF_URGENT\n",
      "ORDER_SPRT | LEARNING_RATES\n",
      "TIME_STEPS | LIST_ACTIVATION\n",
      "LLLR_VERSION | LIST_ALPHA\n",
      "OBLIVIOUS | LIST_AUCLOSS_BURNIN\n",
      "PARAM_MULTIPLET_LOSS | LIST_AUCLOSS_VERSION\n",
      "PARAM_LLR_LOSS | LIST_ACTIVATION_FC\n",
      "MODEL_BACKBONE | LIST_FLAG_MULT\n",
      "ACTIVATION | LIST_IF_ADAPTIVE_LOSS\n",
      "ACTIVATION_FC | LIST_IF_NORMALIZE\n",
      "ALPHA | LIST_IF_POSITIONAL_ENCODING\n",
      "IF_NORMALIZE | LIST_IF_TRAINABLE_ENCODING\n",
      "IF_POSITIONAL_ENCODING | LIST_IF_URGENT\n",
      "IF_TRAINABLE_ENCODING | LIST_LEARNING_RATES\n",
      "ACTIVATION_RECURRENT | LIST_LLLR_VERSION\n",
      "WIDTH_LSTM | LIST_NUM_THRESH\n",
      "NUM_BLOCKS | LIST_OPTIMIZER\n",
      "HEAD_SIZE | LIST_ORDER_SPRT\n",
      "NUM_HEADS | LIST_PARAM_AUSAT_LOSS\n",
      "DROPOUT | LIST_PARAM_LLR_LOSS\n",
      "FF_DIM | LIST_PARAM_MULTIPLET_LOSS\n",
      "MLP_UNITS | LIST_SPARSITY\n",
      "AUCLOSS_VERSION | LIST_ACTIVATION_URGENCY\n",
      "FLAG_MULT | LIST_WEIGHT_DECAY\n",
      "NUM_THRESH | LLLR_VERSION\n",
      "SPARSITY | LR_DECAY_STEPS\n",
      "BETA | LSTM\n",
      "PARAM_AUSAT_LOSS | MAX_TO_KEEP\n",
      "AUCLOSS_BURNIN | MLP_UNITS\n",
      "IF_ADAPTIVE_LOSS | MODEL_BACKBONE\n",
      "ACTIVATION_URGENCY | NAME_DATASET\n",
      "IF_URGENT | NUM_BLOCKS\n",
      "URGENCY_LEVEL | NUM_CLASSES\n",
      "OBJECTIVES | NUM_HEADS\n",
      "OPTIMIZATION_TARGET | NUM_ITER\n",
      "PRUNING_INTERVAL_STEPS | NUM_TEST\n",
      "PRUNER_NAME | NUM_THRESH\n",
      "MAX_TO_KEEP | NUM_TRAIN\n",
      "EXP_PHASE | NUM_TRIALS\n",
      "REPRODUCE_TRIAL | NUM_VAL\n",
      "NUM_TRIALS | OBJECTIVES\n",
      "BATCH_SIZE | OBLIVIOUS\n",
      "LEARNING_RATES | OPTIMIZATION_TARGET\n",
      "LR_DECAY_STEPS | OPTIMIZER\n",
      "WEIGHT_DECAY | ORDER_SPRT\n",
      "OPTIMIZER | PARAM_AUSAT_LOSS\n",
      "NUM_ITER | PARAM_LLR_LOSS\n",
      "TRAIN_DISPLAY_STEP | PARAM_MULTIPLET_LOSS\n",
      "VALIDATION_STEP | PATH_RESUME\n",
      "IF_RESUME | PROJECT_NAME\n",
      "LIST_WEIGHT_DECAY | PRUNER_NAME\n",
      "LIST_LEARNING_RATES | PRUNING_INTERVAL_STEPS\n",
      "LIST_LLLR_VERSION | ACTIVATION_RECURRENT\n",
      "LIST_AUCLOSS_VERSION | REPRODUCE_TRIAL\n",
      "LIST_ACTIVATION | ROOT_CKPTLOGS\n",
      "LIST_ACTIVATION_FC | ROOT_DBLOGS\n",
      "LIST_ACTIVATION_URGENCY | ROOT_DIR\n",
      "LIST_PARAM_MULTIPLET_LOSS | ROOT_IMGLOGS\n",
      "LIST_PARAM_LLR_LOSS | ROOT_TBLOGS\n",
      "LIST_PARAM_AUSAT_LOSS | SAVE_FIGURE\n",
      "LIST_AUCLOSS_BURNIN | SEED\n",
      "LIST_IF_ADAPTIVE_LOSS | SPARSITY\n",
      "LIST_ORDER_SPRT | SUBPROJECT_NAME\n",
      "LIST_ALPHA | TIME_STEPS\n",
      "LIST_IF_POSITIONAL_ENCODING | TRAIN_DISPLAY_STEP\n",
      "LIST_IF_TRAINABLE_ENCODING | TRANSFORMER\n",
      "LIST_OPTIMIZER | ACTIVATION_URGENCY\n",
      "LIST_IF_NORMALIZE | URGENCY_LEVEL\n",
      "LIST_FLAG_MULT | VALIDATION_STEP\n",
      "LIST_NUM_THRESH | VERBOSE\n",
      "LIST_IF_URGENT | WEIGHT_DECAY\n",
      "LIST_SPARSITY | WIDTH_LSTM\n",
      "LSTM | X_PATH\n",
      "TRANSFORMER | Y_PATH\n"
     ]
    }
   ],
   "source": [
    "config_sorted = sort_config(config)\n",
    "for k1, k2 in zip(config.keys(), config_sorted.keys()):\n",
    "    print(f'{k1} | {k2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2e8ae16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LIST_ACTIVATION_RECURRENT': {'CATEGORY_SET': ['tanh', 'sigmoid'],\n",
       "  'PARAM_SPACE': 'categorical'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_sorted['LSTM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f40cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef11902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e2aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76251cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804cd95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0add8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 1.0011060237884521\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class StopWatch:\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.elapsed = time.time() - self.start\n",
    "        print('elapsed time:', self.elapsed)\n",
    "        \n",
    "with StopWatch():\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2832434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_params_from_config(requirements, config):\n",
    "    '''\n",
    "    Extract necessary (hyper)parameters for each function.\n",
    "    The necessary parameters are defined in the set \"reqirements.\"\n",
    "    Use this class to avoid accidentally overwrite the original config function - \n",
    "    remember that python function gets a pointer to the original config dict,\n",
    "    not a copy of it (i.e., config can be modified within a function).\n",
    "    \n",
    "    Args: \n",
    "    - requirements (set): required keys for a given function.\n",
    "    - config (dict): the original dictionary containing all necessary parameters.\n",
    "\n",
    "    Returns:\n",
    "    - sub_conf (class instance): required variables.\n",
    "    '''\n",
    "\n",
    "    # assert that all the required keys exist in the config file.\n",
    "    missing_keys = requirements.difference(config.keys())\n",
    "    assert not missing_keys, f\"Missing necessary parameters: {','.join(missing_keys)}\"\n",
    "\n",
    "    class ExtractParams:\n",
    "        '''\n",
    "        A class to store the required key-value pairs as instance variables.\n",
    "        '''\n",
    "        def __init__(self, **kwargs):\n",
    "            for key, value in kwargs.items():\n",
    "                setattr(self, key.lower(), value)\n",
    "            \n",
    "    sub_conf = ExtractParams(**{key: config[key] for key in requirements})\n",
    "    return sub_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a1b4a6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Missing necessary parameters: IF_",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m      3\u001b[0m requirements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIF_RESUME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPATH_RESUME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIF_RESUME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIF_\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m conf \u001b[38;5;241m=\u001b[39m \u001b[43mextract_params_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mextract_params_from_config\u001b[0;34m(requirements, config)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# assert that all the required keys exist in the config file.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m requirements\u001b[38;5;241m.\u001b[39mdifference(config\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_keys, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing necessary parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing_keys)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mExtractParams\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    A class to store the required key-value pairs as instance variables.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Missing necessary parameters: IF_"
     ]
    }
   ],
   "source": [
    "sys.path.append('/raid6/ebihara/python/SPRTproject/UrgingMAUS')\n",
    "from config.config import config\n",
    "requirements = set(['IF_RESUME', 'PATH_RESUME', 'IF_RESUME'])\n",
    "conf = extract_params_from_config(requirements, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0abc334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IF_', 'IF_RESUME', 'PATH_RESUME'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requirements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
