{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374b011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('/home/afe/Dropbox/PYTHON/SPRTproject/PytorchMAUS_dev/')\n",
    "from utils.misc import StopWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3edd75d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__='2.0.0+cu117'\n",
      "tensor([[ 0.6435,  0.7104,  0.7870,  1.2453,  1.3797,  1.1686,  1.0654,  0.3651,\n",
      "         -0.5143, -1.2671],\n",
      "        [-0.9022,  0.8448,  0.0780,  1.1368,  0.7976, -0.9151,  1.2548,  0.9068,\n",
      "          1.3843,  0.4347],\n",
      "        [ 1.4036, -1.1228,  0.2559,  1.3593, -1.0866, -1.4136,  1.3701,  0.2975,\n",
      "          0.8153,  1.3970],\n",
      "        [ 0.3555,  0.1239, -0.3370,  0.0705,  1.4004,  0.9231,  1.3508,  1.0754,\n",
      "          1.3026,  0.4558],\n",
      "        [ 1.0447,  1.3360,  0.5956, -0.0970,  0.0419,  1.0819,  1.1875,  1.0631,\n",
      "          1.2992,  1.1209],\n",
      "        [ 1.2530, -1.0496,  0.0174,  1.0946,  1.2671,  0.2271,  1.2456, -0.1852,\n",
      "          0.2567,  1.1919],\n",
      "        [ 0.8637,  1.2453,  1.3293,  1.3972,  1.4088,  0.7816,  1.3484,  1.3627,\n",
      "          1.2487,  0.4119],\n",
      "        [ 0.1990,  0.7793,  1.3982,  1.1480,  1.2715,  1.1345,  0.0933,  1.2048,\n",
      "         -0.0655, -1.1045],\n",
      "        [ 0.4058,  1.3997,  1.0866,  1.3754,  1.0477, -0.4980,  1.3130,  1.4081,\n",
      "          1.3935,  1.4019],\n",
      "        [ 1.0619, -0.1916, -1.1597, -0.1214,  1.3893,  0.9007, -0.0993, -0.2852,\n",
      "          1.0026, -0.4531]])\n",
      "tensor([[ 1.2169,  1.3752,  1.2466,  1.0712,  1.1157,  1.3999, -0.8555,  0.6060,\n",
      "          1.3713,  0.8221],\n",
      "        [ 1.4116,  1.2881,  0.6929, -0.0521,  0.5237,  1.3886,  0.1867,  1.1475,\n",
      "          1.2773,  1.3100],\n",
      "        [ 0.9332, -0.0047,  0.3737, -0.2990,  1.3236,  0.6355,  1.4140,  1.3839,\n",
      "         -1.2478,  1.0959],\n",
      "        [ 0.7500, -1.2188,  0.9478,  0.6890,  1.4120,  1.3636,  0.8825,  0.1037,\n",
      "          0.0617,  1.0875],\n",
      "        [ 0.6290,  0.8679, -1.4085,  1.2091,  0.4920,  1.2671,  1.0001,  0.4477,\n",
      "         -0.1234,  0.6799],\n",
      "        [ 0.6291,  1.1506, -0.4995,  1.2626,  1.2545,  0.7360,  1.4077,  0.0273,\n",
      "          0.8958, -0.0765],\n",
      "        [ 0.9925,  1.2200,  1.3895,  0.7182,  1.2802,  0.9787,  0.7565,  1.3761,\n",
      "          1.3658,  1.3366],\n",
      "        [-0.2873,  1.2236, -0.7050, -1.0101,  0.5843,  0.4320,  0.8518,  1.1701,\n",
      "          0.7967,  1.1823],\n",
      "        [-0.1491, -0.1305,  1.3420,  1.2488,  0.2759,  1.0129, -0.2116,  0.7290,\n",
      "          1.3079, -0.6743],\n",
      "        [ 1.0864,  1.1567,  1.2265, -0.4327, -0.5530,  0.3590,  1.1655,  1.3333,\n",
      "          1.2297,  0.8111]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f'{torch.__version__=}')\n",
    "\n",
    "def foo(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(x)\n",
    "    return a + b\n",
    "\n",
    "opt_foo1 = torch.compile(foo)\n",
    "\n",
    "print(opt_foo1(torch.randn(10, 10), torch.randn(10, 10)))\n",
    "\n",
    "@torch.compile\n",
    "def opt_foo2(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(x)\n",
    "    return a + b\n",
    "print(opt_foo2(torch.randn(10, 10), torch.randn(10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33f8ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 20:35:02.644 | INFO     | utils.misc:__exit__:119 - elapsed time: 0.000310804115401374 hours.\n",
      "2023-03-17 20:35:03.181 | INFO     | utils.misc:__exit__:119 - elapsed time: 0.0001489669746822781 hours.\n",
      "2023-03-17 20:35:04.270 | INFO     | utils.misc:__exit__:119 - elapsed time: 0.0003021993901994493 hours.\n"
     ]
    }
   ],
   "source": [
    "with StopWatch():\n",
    "    for _ in range(100000):\n",
    "        opt_foo1(torch.randn(10, 10), torch.randn(10, 10))\n",
    "\n",
    "with StopWatch():\n",
    "    for _ in range(100000):\n",
    "        foo(torch.randn(10, 10), torch.randn(10, 10))\n",
    "\n",
    "with StopWatch():\n",
    "    for _ in range(100000):\n",
    "        opt_foo2(torch.randn(10, 10), torch.randn(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b1d674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (11.7.91)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (11.4.0.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (3.0rc1)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (11.7.4.91)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (4.4.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (59.6.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (0.37.1)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchvision) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchvision) (1.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a30c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the result of running `fn()` and the time it took for `fn()` to run,\n",
    "# in seconds. We use CUDA events and synchronization for the most accurate\n",
    "# measurements.\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000\n",
    "\n",
    "# Generates random input and targets data for the model, where `b` is\n",
    "# batch size.\n",
    "def generate_data(b):\n",
    "    return (\n",
    "        torch.randn(b, 3, 128, 128).to(torch.float32).cuda(),\n",
    "        torch.randint(1000, (b,)).cuda(),\n",
    "    )\n",
    "\n",
    "N_ITERS = 10\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "def init_model():\n",
    "    return resnet18().to(torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a26099cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: 1.4048604736328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:90: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile: 3.546766357421875\n"
     ]
    }
   ],
   "source": [
    "def evaluate(mod, inp):\n",
    "    return mod(inp)\n",
    "\n",
    "model = init_model()\n",
    "\n",
    "# Reset since we are using a different mode.\n",
    "import torch._dynamo\n",
    "torch._dynamo.reset()\n",
    "\n",
    "evaluate_opt = torch.compile(evaluate, mode=\"reduce-overhead\")\n",
    "\n",
    "inp = generate_data(16)[0]\n",
    "print(\"eager:\", timed(lambda: evaluate(model, inp))[1])\n",
    "print(\"compile:\", timed(lambda: evaluate_opt(model, inp))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63392c97",
   "metadata": {},
   "source": [
    "# SPRT-TANDEM speedtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b70db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 02:47:33.847174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX_VNNI\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/lib/python3/dist-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "2023-03-20 02:47:34.529 | INFO     | utils.misc:create_directories_and_log:182 - \u001b[33mA new log directory was created: \u001b[0m/home/afe/Dropbox/PYTHON/SPRTproject/PytorchMAUS_dev/logs/test_offset2.0_optimausat_confmx_Transformer_try/checkpoints/_20230320_024734528/configs\n",
      "2023-03-20 02:47:34.529 | INFO     | utils.misc:create_directories_and_log:182 - \u001b[33mA new log directory was created: \u001b[0m/home/afe/Dropbox/PYTHON/SPRTproject/PytorchMAUS_dev/logs/test_offset2.0_optimausat_confmx_Transformer_try/TensorBoard_events/_20230320_024734528\n",
      "2023-03-20 02:47:34.530 | INFO     | utils.misc:create_directories_and_log:182 - \u001b[33mA new log directory was created: \u001b[0m/home/afe/Dropbox/PYTHON/SPRTproject/PytorchMAUS_dev/logs/test_offset2.0_optimausat_confmx_Transformer_try/image_logs/_20230320_024734528\n",
      "2023-03-20 02:47:34.538 | INFO     | models.temporal_integrators:summarize:391 - \n",
      ":'######::'########::'########::'########::::::::::::::::::::::\n",
      "'##... ##: ##.... ##: ##.... ##:... ##..:::::::::::::::::::::::\n",
      " ##:::..:: ##:::: ##: ##:::: ##:::: ##:::::::::::::::::::::::::\n",
      ". ######:: ########:: ########::::: ##::::'#######:::::::::::::\n",
      ":..... ##: ##.....::: ##.. ##:::::: ##::::........:::::::::::::\n",
      "'##::: ##: ##:::::::: ##::. ##::::: ##:::::::::::::::::::::::::\n",
      ". ######:: ##:::::::: ##:::. ##:::: ##:::::::::::::::::::::::::\n",
      ":......:::..:::::::::..:::::..:::::..::::::::::::::::::::::::::\n",
      "'########::::'###::::'##::: ##:'########::'########:'##::::'##:\n",
      "... ##..::::'## ##::: ###:: ##: ##.... ##: ##.....:: ###::'###:\n",
      "::: ##:::::'##:. ##:: ####: ##: ##:::: ##: ##::::::: ####'####:\n",
      "::: ##::::'##:::. ##: ## ## ##: ##:::: ##: ######::: ## ### ##:\n",
      "::: ##:::: #########: ##. ####: ##:::: ##: ##...:::: ##. #: ##:\n",
      "::: ##:::: ##.... ##: ##:. ###: ##:::: ##: ##::::::: ##:.:: ##:\n",
      "::: ##:::: ##:::: ##: ##::. ##: ########:: ########: ##:::: ##:\n",
      ":::..:::::..:::::..::..::::..::........:::........::..:::::..::\n",
      "\n",
      "2023-03-20 02:47:34.539 | INFO     | models.temporal_integrators:summarize:393 - \u001b[34mofficial PyTorch implementation.\u001b[0m\n",
      "/home/afe/Dropbox/PYTHON/SPRTproject/PytorchMAUS_dev/models/temporal_integrators.py:226: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert x.shape[-1] == self.feat_dim\n",
      "2023-03-20 02:47:34.680 | INFO     | models.temporal_integrators:summarize:403 - model summary:\n",
      "TANDEMformer(\n",
      "  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (activation_logit): ReLU()\n",
      "  (decoder): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc_logits): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "2023-03-20 02:47:34.686 | INFO     | models.temporal_integrators:summarize:404 - input shape: torch.Size([100, 2, 128])\n",
      "2023-03-20 02:47:34.686 | INFO     | models.temporal_integrators:summarize:405 - output shape: torch.Size([100, 2, 3])\n",
      "2023-03-20 02:47:34.686 | INFO     | models.temporal_integrators:summarize:406 - Number of trainable parameters:, 174979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "device=device(type='cuda')\n",
      "/home/afe/Dropbox/PYTHON/SPRTproject/PytorchMAUS_dev/logs/test_offset2.0_optimausat_confmx_Transformer_try/TensorBoard_events/_20230320_024734528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 02:47:35.570 | INFO     | models.temporal_integrators:import_model:54 - model moved onto: \u001b[33mcuda.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys, os, pdb\n",
    "sys.path.append('/home/afe/Dropbox/PYTHON/SPRTproject/PytorchMAUS_dev/')\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "from loguru import logger\n",
    "from config.config import config\n",
    "# config['DATA_PATH'] = '/Users/AFE/Dropbox/PYTHON/data/SDRE_data/x_batch_30000_3class_offset2.0.npy'\n",
    "# config['X_PATH'] = f'/Users/AFE/Dropbox/PYTHON/data/SDRE_data/x_batch_30000_3class_offset2.0.npy'\n",
    "# config['Y_PATH'] = f'/Users/AFE/Dropbox/PYTHON/data/SDRE_data/y_batch_30000_3class_offset2.0.npy'\n",
    "# config['GT_LLR_PATH'] = f'/Users/AFE/Dropbox/PYTHON/data/SDRE_data/gt_llrms_30000_3class_offset2.0.npy'\n",
    "    \n",
    "from utils.misc import grab_gpu, fix_random_seed, parse_args, extract_params_from_config, StopWatch\n",
    "from utils.logging import create_log_folders, save_config_info, ContexualLogger,\\\n",
    "                          save_sdre_imgs, log_training_results, get_tb_writer\n",
    "from utils.hyperparameter_tuning import run_optuna, suggest_parameters_optuna, report_to_pruner\n",
    "from utils.checkpoint import update_and_save_result, \\\n",
    "                             initialize_objectives, finalize_objectives\n",
    "from datasets.data_processing import SequentialDensityRatioData, slice_data, move_to_device, numpy_to_torch\n",
    "from models.temporal_integrators import import_model\n",
    "from models.optimizers import initialize_optimizer\n",
    "from models.losses import compute_loss_and_metrics, multiply_diff_mht\n",
    "from utils.performance_metrics import llr_sequential_confmx, seqconfmx_to_macro_ave_sns,\\\n",
    "                                calc_llr_abserr, average_dicts\n",
    "from utils.misc import PyTorchPhaseManager\n",
    "\n",
    "import  matplotlib.pyplot as plt\n",
    "# parse_args(config)\n",
    "device = grab_gpu(config) \n",
    "print(f'{device=}')\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "create_log_folders(config) # This function modifies config\n",
    "\n",
    "# config['IS_SEED'] = True\n",
    "# fix_random_seed(config)\n",
    "\n",
    "# is_losscoef_all_zero = suggest_parameters_optuna(trial, config)  # This function may modify config\n",
    "print(config['DIR_TBLOGS'])\n",
    "save_config_info(config) # save config.py and config (dict) for reproducibility\n",
    "\n",
    "    \n",
    "tb_writer = get_tb_writer(config)\n",
    "model = import_model(config, device, tb_writer) # initialize the network or load a pretrained one\n",
    "# opt_model = torch.compile(model, mode='max-autotune')\n",
    "# print(model)\n",
    "# print(opt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf452aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_slice.shape=torch.Size([4900, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "def numpy_to_torch(*args):\n",
    "    \"\"\"\n",
    "    Convert numpy arrays to PyTorch tensors.\n",
    "\n",
    "    Args:\n",
    "        *args: One or more inputs to be converted.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the converted inputs.\n",
    "    \"\"\"\n",
    "    converted_args = []\n",
    "    for arg in args:\n",
    "        if isinstance(arg, np.ndarray):\n",
    "            arg = torch.from_numpy(arg)\n",
    "        arg.to(device)\n",
    "        converted_args.append(arg)\n",
    "    return tuple(converted_args)\n",
    "\n",
    "def sequential_slice(x, y, order_sprt):\n",
    "    \"\"\"Slice, copy, and concat a batch to make a time-sliced, augumented batch\n",
    "    Effective batch size will be batch * (duration - order_sprt)).\n",
    "    e.g., nosaic MNIST and 2nd-order SPRT: \n",
    "        effective batch size is (20-2)=18 times larger than the original batch size.\n",
    "    Args:\n",
    "        x: A Tensor with shape (batch, duration, feature dimension).\n",
    "        y: A Tensor with shape (batch).\n",
    "        order_sprt: An int. The order of SPRT.\n",
    "    Returns:\n",
    "        x_slice: A Tensor with shape (batch*(duration-order_sprt), order_sprt+1, feat dim).\n",
    "        y_slice: A Tensor with shape (batch*(duration-order_sprt),).\n",
    "    Remark:\n",
    "        y_slice may be a confusing name, because we copy and concatenate original y to obtain y_slice.\n",
    "    \"\"\"\n",
    "    x, y = numpy_to_torch(x, y)\n",
    "    \n",
    "    duration = x.shape[1]\n",
    "\n",
    "    if duration < order_sprt + 1:\n",
    "        raise ValueError(\"order_sprt must be <= duration - 1. Now order_sprt={}, duration={} .\".format(order_sprt, duration))\n",
    "\n",
    "    for i in range(duration - order_sprt):\n",
    "        if i == 0:\n",
    "            x_slice = x[:, i:i+order_sprt+1, :]\n",
    "            y_slice = y\n",
    "        else:\n",
    "            x_slice = torch.cat([x_slice, x[:, i:i+order_sprt+1, :]],0)\n",
    "            y_slice = torch.cat([y_slice, y], 0)\n",
    "\n",
    "    return x_slice, y_slice\n",
    "\n",
    "x_batch = np.load('x_batch.npy')\n",
    "y_batch = np.load('y_batch.npy')\n",
    "llrs = np.load('llrs.npy')\n",
    "x_batch, y_batch, llrs = numpy_to_torch(x_batch, y_batch, llrs)\n",
    "x_batch, y_batch, llrs = move_to_device(device, x_batch, y_batch, llrs)\n",
    "x_slice, y_slice = sequential_slice(x_batch, y_batch, config['ORDER_SPRT'])\n",
    "\n",
    "logits_slice = model(x_slice)\n",
    "\n",
    "print(f'{logits_slice.shape=}')\n",
    "# print(f'{urgency_signal.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac6a697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 02:48:00.932 | INFO     | datasets.data_processing:__init__:19 - Loading SDRE data. This may take a while...\n"
     ]
    }
   ],
   "source": [
    "data = SequentialDensityRatioData(config) # load the data!\n",
    "num_trials = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01265a5e",
   "metadata": {},
   "source": [
    "# Optimized model with PyTorchPhaseManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e7f52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10135/461033264.py:1: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  torch.autograd.detect_anomaly()\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.detect_anomaly()\n",
    "\n",
    "optimizer, schedular = initialize_optimizer(model, config)\n",
    "\n",
    "global_step = 1\n",
    "# Decode features and move to the device\n",
    "x_batch, y_batch, gt_llrs_batch = slice_data(data, device, phase='training', iter=global_step, \n",
    "                                             batch_size=config['BATCH_SIZE'])\n",
    "x_batch, y_batch, llrs = numpy_to_torch(x_batch, y_batch, llrs)\n",
    "x_batch, y_batch, llrs = move_to_device(device, x_batch, y_batch, llrs)\n",
    "x_slice, y_slice = sequential_slice(x_batch, y_batch, config['ORDER_SPRT'])\n",
    "logits_slice = model(x_slice)\n",
    "loss = torch.abs(torch.max(logits_slice) - torch.max(llrs))\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52628e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:93: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n",
      "[2023-03-20 02:48:46,620] torch._inductor.utils: [WARNING] not enough cuda cores to use max_autotune_gemm mode\n"
     ]
    }
   ],
   "source": [
    "mode = 'default' #'reduce-overhead' #'default' # 'max-autotune' \n",
    "opt_model = torch.compile(model, mode=mode)\n",
    "\n",
    "optimizer, schedular = initialize_optimizer(opt_model, config)\n",
    "\n",
    "global_step = 1\n",
    "# Decode features and move to the device\n",
    "x_batch, y_batch, gt_llrs_batch = slice_data(data, device, phase='training', iter=global_step, \n",
    "                                             batch_size=config['BATCH_SIZE'])\n",
    "x_batch, y_batch, llrs = numpy_to_torch(x_batch, y_batch, llrs)\n",
    "x_batch, y_batch, llrs = move_to_device(device, x_batch, y_batch, llrs)\n",
    "x_slice, y_slice = sequential_slice(x_batch, y_batch, config['ORDER_SPRT'])\n",
    "logits_slice = opt_model(x_slice)\n",
    "loss = torch.abs(torch.max(logits_slice) - torch.max(llrs))\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "918714b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.loss=tensor(173.8226, device='cuda:0', grad_fn=<AbsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 11:26:18.303 | INFO     | utils.misc:__exit__:140 - elapsed time: 88.8623948097229 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.loss=tensor(0.0592, device='cuda:0', grad_fn=<AbsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# max-autotune 100 iter, LSTM order=5: 0.89011 sec.\n",
    "# reduce-overhead 100 iter, LSTM order=5: 0.88374 sec\n",
    "# default 100 iter, LSTM order=5: 0.88106 sec\n",
    "mode = 'max-autotune' #'reduce-overhead' #'default' # 'max-autotune' \n",
    "opt_model = torch.compile(model, mode=mode)\n",
    "\n",
    "optimizer, schedular = initialize_optimizer(opt_model, config)\n",
    "\n",
    "with StopWatch('sec'):\n",
    "    for global_step in range(num_trials):\n",
    "        # Decode features and move to the device\n",
    "        x_batch, y_batch, gt_llrs_batch = slice_data(data, device, phase='training', iter=global_step, \n",
    "                                                     batch_size=config['BATCH_SIZE'])\n",
    "        x_batch, y_batch, llrs = numpy_to_torch(x_batch, y_batch, llrs)\n",
    "        x_batch, y_batch, llrs = move_to_device(device, x_batch, y_batch, llrs)\n",
    "        # Train phase: run preprocesses (model.train(), optimizer.zero_grad()) and postprocesses (optimizer.step(), loss.backward())\n",
    "        # Eval phase: run preprocesses (model.eval()), enter torch.no_grad() mode    \n",
    "        with PyTorchPhaseManager(opt_model, optimizer, phase='train') as p:\n",
    "            x_slice, y_slice = sequential_slice(x_batch, y_batch, config['ORDER_SPRT'])\n",
    "            logits_slice, urgency_signal = p.model(x_slice)\n",
    "            p.loss = torch.abs(torch.max(logits_slice) - torch.max(llrs))\n",
    "            if global_step == 0 or global_step == num_trials-1:\n",
    "                print(f'{p.loss=}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9810a8",
   "metadata": {},
   "source": [
    "# default model with PyTorchPhaseManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e40304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.loss=tensor(205.2694, device='cuda:0', grad_fn=<AbsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 11:22:43.210 | INFO     | utils.misc:__exit__:140 - elapsed time: 2.881443977355957 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.loss=tensor(201.8043, device='cuda:0', grad_fn=<AbsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# default 100 iter, LSTM order=5: 3.778 sec.\n",
    "optimizer, schedular = initialize_optimizer(model, config)\n",
    "\n",
    "with StopWatch('sec'):\n",
    "    for global_step in range(num_trials):\n",
    "        # Decode features and move to the device\n",
    "        x_batch, y_batch, gt_llrs_batch = slice_data(data, device, phase='training', iter=global_step, \n",
    "                                                     batch_size=config['BATCH_SIZE'])\n",
    "        x_batch, y_batch, llrs = numpy_to_torch(x_batch, y_batch, llrs)\n",
    "        x_batch, y_batch, llrs = move_to_device(device, x_batch, y_batch, llrs)\n",
    "        # Train phase: run preprocesses (model.train(), optimizer.zero_grad()) and postprocesses (optimizer.step(), loss.backward())\n",
    "        # Eval phase: run preprocesses (model.eval()), enter torch.no_grad() mode    \n",
    "        with PyTorchPhaseManager(model, optimizer, phase='train') as p:\n",
    "            x_slice, y_slice = sequential_slice(x_batch, y_batch, config['ORDER_SPRT'])\n",
    "            logits_slice, urgency_signal = p.model(x_slice)\n",
    "            p.loss = torch.abs(torch.max(logits_slice) - torch.max(llrs))\n",
    "            if global_step == 0 or global_step == num_trials-1:\n",
    "                print(f'{p.loss=}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04358474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.288016707148208"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.778 / 0.88106"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076729b6",
   "metadata": {},
   "source": [
    "# Without optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 100\n",
    "\n",
    "optimizer, schedular = initialize_optimizer(model, config)\n",
    "with StopWatch(unit='sec'):\n",
    "    for i in range(num_runs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        logits_slice, urgency_signal = model(x_slice)\n",
    "        loss = torch.mean(logits_slice) - torch.mean(llrs)\n",
    "        optimizer.step()\n",
    "        loss.backward(retain_graph=True)\n",
    "        if i == 0 or i == num_runs-1:\n",
    "            print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e02be41",
   "metadata": {},
   "source": [
    "# With optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 100\n",
    "\n",
    "mode = 'default' #'max_autotune'\n",
    "opt_model = torch.compile(model, mode=mode)\n",
    "# opt_model = model\n",
    "# del optimizer\n",
    "\n",
    "optimizer, schedular = initialize_optimizer(opt_model, config)\n",
    "with StopWatch(unit='sec'):\n",
    "    for i in range(num_runs):\n",
    "        opt_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        logits_slice, urgency_signal = opt_model(x_slice)\n",
    "        loss = torch.mean(logits_slice) - torch.mean(llrs)\n",
    "        optimizer.step()\n",
    "        loss.backward(retain_graph=True)\n",
    "        if i == 0 or i == num_runs-1:\n",
    "            print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh\n",
    "del model, opt_model, optimizer\n",
    "model = import_model(config, device, tb_writer) # initialize the network or load a pretrained one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eed524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729cc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706dbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
