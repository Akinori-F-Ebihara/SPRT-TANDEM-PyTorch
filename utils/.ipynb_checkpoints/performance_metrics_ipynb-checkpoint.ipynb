{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from __future__ import absolute_import\n",
                "from __future__ import division\n",
                "from __future__ import print_function\n",
                "\n",
                "import tensorflow as tf\n",
                "import numpy as np\n",
                "def set_gpu_devices(gpu):\n",
                "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
                "    assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
                "    tf.config.experimental.set_visible_devices(physical_devices[gpu], 'GPU')\n",
                "    tf.config.experimental.set_memory_growth(physical_devices[gpu], True)\n",
                "set_gpu_devices(0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sequential_concat(x_slice, y_slice, duration=20):\n",
                "    \"\"\"Opposite operation of sequential_slice. \n",
                "    x_slice's shape will change \n",
                "    from (batch * (duration - order_sprt), order_sprt + 1, feat dim )\n",
                "    to  (batch, (duration - order_sprt), order_sprt + 1, feat dim).\n",
                "    y changes accordingly.\n",
                "    Args:\n",
                "        x_slice: A Tensor with shape (batch * (duration - order_sprt), order_sprt + 1, feat dim). This is the output of models.backbones_lstm.LSTMModel.__call__(inputs, training). \n",
                "        y_slice: A Tensor with shape (batch*(duration - order_sprt),).\n",
                "        duration: An int. 20 for nosaic MNIST.\n",
                "    Returns:\n",
                "        x_cocnat: A Tensor with shape (batch, (duration - order_sprt), order_sprt + 1, feat dim).\n",
                "        y_concat: A Tensor with shape (batch).\n",
                "    \"\"\"\n",
                "    x_shape = x_slice.shape\n",
                "    order_sprt = int(x_shape[1] - 1)\n",
                "    batch = int(x_shape[0] / (duration - order_sprt))\n",
                "    feat_dim = x_shape[-1]\n",
                "\n",
                "    # Cancat time-sliced, augumented batch\n",
                "    x_concat = tf.reshape(x_slice, (duration - order_sprt, batch, order_sprt + 1, feat_dim))\n",
                "    x_concat = tf.transpose(x_concat, [1, 0, 2, 3]) # (batch, duration - order_sprt, order_sprt + 1, feat_dim)\n",
                "    y_concat = y_slice[:batch]\n",
                "\n",
                "    return x_concat, y_concat\n",
                "\n",
                "def _sequentially_calc_binary_llrs(logits_concat):\n",
                "    \"\"\"Calculate the frame-by-frame confusion matrices based on the log-likelihood ratios.\n",
                "    Args:\n",
                "        logits_concat: A logit Tensor with shape (batch, (duration - order_sprt), order_sprt + 1, 2). This is the output of utils.data_processing.sequential_concat(logit_slice, labels_slice).\n",
                "    Returns:\n",
                "        dict_llrs: A dictionary of log-likelihood ratio Tensors. Only the order_sprt-th order, not all order.\n",
                "    Remark:\n",
                "        - Binary classification (num classes = 2) is assumed.\n",
                "    \"\"\"\n",
                "    logits_concat_shape = logits_concat.shape\n",
                "\n",
                "    # Start calc of LLR loss. See the N-th-order SPRT formula.\n",
                "    order_sprt = int(logits_concat_shape[2] - 1)\n",
                "    duration = int(logits_concat_shape[1] + order_sprt)\n",
                "    dict_llrs = dict()\n",
                "\n",
                "    for iter_frame in range(duration):\n",
                "        # i.i.d. SPRT (0th-order SPRT)\n",
                "        if order_sprt == 0:\n",
                "            llrs_all_frames = logits_concat[:, :, order_sprt, 1] - logits_concat[:, :, order_sprt, 0] # (batch, duration-order_sprt, order_sprt+1, nb_cls=2) -> (batch, duration-order_sprt)\n",
                "            llrs = tf.reduce_sum(llrs_all_frames[:, :iter_frame+1], -1) # (batch,)\n",
                "            dict_llrs[\"llr_{}th_order_frame{:03d}\".format(\"000\", iter_frame+1)] = llrs\n",
                "\n",
                "        # N-th-order SPRT\n",
                "        else:\n",
                "            if iter_frame < order_sprt + 1:\n",
                "                llrs = logits_concat[:, 0, iter_frame, 1] - logits_concat[:, 0, iter_frame, 0] \n",
                "                dict_llrs[\"llr_{:03d}th_order_frame{:03d}\".format(order_sprt, iter_frame+1)] = llrs\n",
                "\n",
                "            else:\n",
                "                llrs1 = logits_concat[:, :iter_frame, order_sprt, 1] - logits_concat[:, :iter_frame, order_sprt, 0] # (batch, iter_frame)\n",
                "                llrs1 = tf.reduce_sum(llrs1, -1) # (batch,)\n",
                "                llrs2 = logits_concat[:, 1:iter_frame, order_sprt-1, 1] - logits_concat[:, 1:iter_frame, order_sprt-1, 0] # (batch, iter_frame-1)\n",
                "                llrs2 = tf.reduce_sum(llrs2, -1) # (batch,)\n",
                "                llrs = llrs1 - llrs2 # (batch, )\n",
                "                dict_llrs[\"llr_{:03d}th_order_frame{:03d}\".format(order_sprt, iter_frame+1)] = llrs\n",
                "\n",
                "    return dict_llrs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[[0.4555872  0.80769406]\n",
                        "  [0.21401404 0.21298602]\n",
                        "  [0.54932954 0.44270126]\n",
                        "  [0.92474932 0.45696688]\n",
                        "  [0.66159267 0.23012716]\n",
                        "  [0.90822107 0.0534633 ]\n",
                        "  [0.15924537 0.16743213]\n",
                        "  [0.57618239 0.858917  ]\n",
                        "  [0.05886835 0.52406228]\n",
                        "  [0.16078754 0.46109362]\n",
                        "  [0.6392866  0.02212261]\n",
                        "  [0.03224048 0.23299577]\n",
                        "  [0.2233559  0.18707425]\n",
                        "  [0.39689337 0.81043285]\n",
                        "  [0.22554088 0.95713654]\n",
                        "  [0.55684142 0.44890078]\n",
                        "  [0.35851801 0.54158167]\n",
                        "  [0.36457194 0.88120864]\n",
                        "  [0.17070167 0.43887175]\n",
                        "  [0.49051366 0.64076217]]\n",
                        "\n",
                        " [[0.32640182 0.26471594]\n",
                        "  [0.58733699 0.57063145]\n",
                        "  [0.03227289 0.12678464]\n",
                        "  [0.74592963 0.24596626]\n",
                        "  [0.05214763 0.72570692]\n",
                        "  [0.24775064 0.15336312]\n",
                        "  [0.09577495 0.37922493]\n",
                        "  [0.84594573 0.41747837]\n",
                        "  [0.58004797 0.23566674]\n",
                        "  [0.41203506 0.01800845]\n",
                        "  [0.76823589 0.83605781]\n",
                        "  [0.86238905 0.68698813]\n",
                        "  [0.10239206 0.91056564]\n",
                        "  [0.95286417 0.09652983]\n",
                        "  [0.37795248 0.98080644]\n",
                        "  [0.88838314 0.65193546]\n",
                        "  [0.69810418 0.56829116]\n",
                        "  [0.20478651 0.98007408]\n",
                        "  [0.90343021 0.02791377]\n",
                        "  [0.08335554 0.7354774 ]]\n",
                        "\n",
                        " [[0.92688303 0.04346203]\n",
                        "  [0.42547932 0.49580213]\n",
                        "  [0.91354121 0.83302758]\n",
                        "  [0.88433861 0.44701051]\n",
                        "  [0.59779838 0.25855556]\n",
                        "  [0.79207947 0.37542822]\n",
                        "  [0.95410021 0.7475644 ]\n",
                        "  [0.34683691 0.5146922 ]\n",
                        "  [0.07403215 0.48887519]\n",
                        "  [0.75491156 0.55366683]\n",
                        "  [0.97472083 0.32714887]\n",
                        "  [0.79528345 0.46061131]\n",
                        "  [0.86274137 0.3927031 ]\n",
                        "  [0.23342349 0.59720071]\n",
                        "  [0.46460299 0.9760224 ]\n",
                        "  [0.72533411 0.60995085]\n",
                        "  [0.72819709 0.61310789]\n",
                        "  [0.70526631 0.41216316]\n",
                        "  [0.41893148 0.51868918]\n",
                        "  [0.40167039 0.55696772]]\n",
                        "\n",
                        " [[0.7648296  0.56866797]\n",
                        "  [0.06725231 0.45360707]\n",
                        "  [0.92807128 0.72847403]\n",
                        "  [0.5823922  0.14810733]\n",
                        "  [0.21459362 0.54850945]\n",
                        "  [0.81370578 0.36607215]\n",
                        "  [0.49846668 0.54239299]\n",
                        "  [0.98440516 0.98701262]\n",
                        "  [0.15976355 0.16324018]\n",
                        "  [0.3921471  0.25613054]\n",
                        "  [0.01347106 0.17815908]\n",
                        "  [0.99207055 0.2336226 ]\n",
                        "  [0.07096387 0.74576998]\n",
                        "  [0.02050015 0.22317892]\n",
                        "  [0.99693718 0.35757453]\n",
                        "  [0.9771535  0.3292897 ]\n",
                        "  [0.79641923 0.833084  ]\n",
                        "  [0.60314331 0.62629421]\n",
                        "  [0.6594949  0.43910082]\n",
                        "  [0.68539617 0.76275274]]]\n",
                        "[0, 1, 0, 1]\n"
                    ]
                }
            ],
            "source": [
                "# Example dummy data\n",
                "batch = 4\n",
                "duration = 20\n",
                "order_sprt = 19\n",
                "nb_cls = 2\n",
                "feat_dim = nb_cls\n",
                "assert duration >= order_sprt + 1\n",
                "\n",
                "#data = [k for k in range(batch*duration*feat_dim)]\n",
                "data = np.random.rand(batch*duration*feat_dim)\n",
                "data = np.reshape(data, (batch, duration, feat_dim))\n",
                "label = [k%nb_cls for k in range(batch)]\n",
                "print(data) # (batch, duration, feat_dim)\n",
                "print(label) # (batch,)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tf.Tensor(\n",
                        "[[[0.4555872  0.8076941 ]\n",
                        "  [0.21401404 0.21298602]\n",
                        "  [0.5493295  0.44270125]\n",
                        "  [0.9247493  0.45696688]\n",
                        "  [0.66159266 0.23012716]\n",
                        "  [0.90822107 0.0534633 ]\n",
                        "  [0.15924537 0.16743213]\n",
                        "  [0.57618237 0.858917  ]\n",
                        "  [0.05886836 0.5240623 ]\n",
                        "  [0.16078754 0.46109363]\n",
                        "  [0.6392866  0.02212261]\n",
                        "  [0.03224048 0.23299578]\n",
                        "  [0.2233559  0.18707426]\n",
                        "  [0.39689335 0.81043285]\n",
                        "  [0.22554088 0.9571365 ]\n",
                        "  [0.55684143 0.4489008 ]\n",
                        "  [0.358518   0.5415817 ]\n",
                        "  [0.36457193 0.88120866]\n",
                        "  [0.17070167 0.43887174]\n",
                        "  [0.49051365 0.64076215]]\n",
                        "\n",
                        " [[0.32640183 0.26471594]\n",
                        "  [0.587337   0.57063144]\n",
                        "  [0.03227289 0.12678464]\n",
                        "  [0.74592966 0.24596626]\n",
                        "  [0.05214763 0.72570693]\n",
                        "  [0.24775064 0.15336312]\n",
                        "  [0.09577495 0.37922493]\n",
                        "  [0.8459457  0.41747838]\n",
                        "  [0.58004797 0.23566674]\n",
                        "  [0.41203505 0.01800845]\n",
                        "  [0.7682359  0.83605784]\n",
                        "  [0.862389   0.6869881 ]\n",
                        "  [0.10239206 0.9105656 ]\n",
                        "  [0.95286417 0.09652983]\n",
                        "  [0.3779525  0.98080647]\n",
                        "  [0.88838315 0.65193546]\n",
                        "  [0.6981042  0.5682912 ]\n",
                        "  [0.20478651 0.9800741 ]\n",
                        "  [0.9034302  0.02791377]\n",
                        "  [0.08335554 0.7354774 ]]\n",
                        "\n",
                        " [[0.92688304 0.04346203]\n",
                        "  [0.42547932 0.49580213]\n",
                        "  [0.9135412  0.8330276 ]\n",
                        "  [0.8843386  0.44701052]\n",
                        "  [0.5977984  0.25855556]\n",
                        "  [0.79207945 0.37542823]\n",
                        "  [0.9541002  0.7475644 ]\n",
                        "  [0.3468369  0.5146922 ]\n",
                        "  [0.07403215 0.48887518]\n",
                        "  [0.75491154 0.55366683]\n",
                        "  [0.97472084 0.32714888]\n",
                        "  [0.79528344 0.4606113 ]\n",
                        "  [0.86274135 0.39270312]\n",
                        "  [0.23342349 0.5972007 ]\n",
                        "  [0.46460298 0.9760224 ]\n",
                        "  [0.7253341  0.60995084]\n",
                        "  [0.7281971  0.6131079 ]\n",
                        "  [0.7052663  0.41216317]\n",
                        "  [0.41893148 0.51868916]\n",
                        "  [0.4016704  0.55696774]]\n",
                        "\n",
                        " [[0.7648296  0.56866795]\n",
                        "  [0.06725232 0.45360708]\n",
                        "  [0.92807126 0.728474  ]\n",
                        "  [0.5823922  0.14810733]\n",
                        "  [0.21459362 0.5485094 ]\n",
                        "  [0.8137058  0.36607215]\n",
                        "  [0.49846667 0.54239297]\n",
                        "  [0.98440516 0.9870126 ]\n",
                        "  [0.15976356 0.16324018]\n",
                        "  [0.3921471  0.25613055]\n",
                        "  [0.01347106 0.17815907]\n",
                        "  [0.99207056 0.23362261]\n",
                        "  [0.07096387 0.74577   ]\n",
                        "  [0.02050015 0.22317892]\n",
                        "  [0.99693716 0.35757452]\n",
                        "  [0.9771535  0.3292897 ]\n",
                        "  [0.7964192  0.833084  ]\n",
                        "  [0.60314333 0.6262942 ]\n",
                        "  [0.6594949  0.43910083]\n",
                        "  [0.6853962  0.7627527 ]]], shape=(4, 20, 2), dtype=float32)\n",
                        "tf.Tensor([0 1 0 1], shape=(4,), dtype=int32)\n"
                    ]
                }
            ],
            "source": [
                "# Slice and concat a batch to make a time-sliced, augumented bathch\n",
                "for i in range(duration - order_sprt):\n",
                "    if i == 0:\n",
                "        data_timeslice = data[:, i:i+order_sprt+1, :]\n",
                "        label_timeslice = label\n",
                "    else:\n",
                "        data_timeslice = tf.concat([data_timeslice, data[:, i:i+order_sprt+1, :]],0)\n",
                "        label_timeslice = tf.concat([label_timeslice, label], 0)\n",
                "data_timeslice = tf.cast(data_timeslice, tf.float32)\n",
                "label_timeslice = tf.cast(label_timeslice, tf.int32)\n",
                "print(data_timeslice)\n",
                "print(label_timeslice)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tf.Tensor(\n",
                        "[[[[0.4555872  0.8076941 ]\n",
                        "   [0.21401404 0.21298602]\n",
                        "   [0.5493295  0.44270125]\n",
                        "   [0.9247493  0.45696688]\n",
                        "   [0.66159266 0.23012716]\n",
                        "   [0.90822107 0.0534633 ]\n",
                        "   [0.15924537 0.16743213]\n",
                        "   [0.57618237 0.858917  ]\n",
                        "   [0.05886836 0.5240623 ]\n",
                        "   [0.16078754 0.46109363]\n",
                        "   [0.6392866  0.02212261]\n",
                        "   [0.03224048 0.23299578]\n",
                        "   [0.2233559  0.18707426]\n",
                        "   [0.39689335 0.81043285]\n",
                        "   [0.22554088 0.9571365 ]\n",
                        "   [0.55684143 0.4489008 ]\n",
                        "   [0.358518   0.5415817 ]\n",
                        "   [0.36457193 0.88120866]\n",
                        "   [0.17070167 0.43887174]\n",
                        "   [0.49051365 0.64076215]]]\n",
                        "\n",
                        "\n",
                        " [[[0.32640183 0.26471594]\n",
                        "   [0.587337   0.57063144]\n",
                        "   [0.03227289 0.12678464]\n",
                        "   [0.74592966 0.24596626]\n",
                        "   [0.05214763 0.72570693]\n",
                        "   [0.24775064 0.15336312]\n",
                        "   [0.09577495 0.37922493]\n",
                        "   [0.8459457  0.41747838]\n",
                        "   [0.58004797 0.23566674]\n",
                        "   [0.41203505 0.01800845]\n",
                        "   [0.7682359  0.83605784]\n",
                        "   [0.862389   0.6869881 ]\n",
                        "   [0.10239206 0.9105656 ]\n",
                        "   [0.95286417 0.09652983]\n",
                        "   [0.3779525  0.98080647]\n",
                        "   [0.88838315 0.65193546]\n",
                        "   [0.6981042  0.5682912 ]\n",
                        "   [0.20478651 0.9800741 ]\n",
                        "   [0.9034302  0.02791377]\n",
                        "   [0.08335554 0.7354774 ]]]\n",
                        "\n",
                        "\n",
                        " [[[0.92688304 0.04346203]\n",
                        "   [0.42547932 0.49580213]\n",
                        "   [0.9135412  0.8330276 ]\n",
                        "   [0.8843386  0.44701052]\n",
                        "   [0.5977984  0.25855556]\n",
                        "   [0.79207945 0.37542823]\n",
                        "   [0.9541002  0.7475644 ]\n",
                        "   [0.3468369  0.5146922 ]\n",
                        "   [0.07403215 0.48887518]\n",
                        "   [0.75491154 0.55366683]\n",
                        "   [0.97472084 0.32714888]\n",
                        "   [0.79528344 0.4606113 ]\n",
                        "   [0.86274135 0.39270312]\n",
                        "   [0.23342349 0.5972007 ]\n",
                        "   [0.46460298 0.9760224 ]\n",
                        "   [0.7253341  0.60995084]\n",
                        "   [0.7281971  0.6131079 ]\n",
                        "   [0.7052663  0.41216317]\n",
                        "   [0.41893148 0.51868916]\n",
                        "   [0.4016704  0.55696774]]]\n",
                        "\n",
                        "\n",
                        " [[[0.7648296  0.56866795]\n",
                        "   [0.06725232 0.45360708]\n",
                        "   [0.92807126 0.728474  ]\n",
                        "   [0.5823922  0.14810733]\n",
                        "   [0.21459362 0.5485094 ]\n",
                        "   [0.8137058  0.36607215]\n",
                        "   [0.49846667 0.54239297]\n",
                        "   [0.98440516 0.9870126 ]\n",
                        "   [0.15976356 0.16324018]\n",
                        "   [0.3921471  0.25613055]\n",
                        "   [0.01347106 0.17815907]\n",
                        "   [0.99207056 0.23362261]\n",
                        "   [0.07096387 0.74577   ]\n",
                        "   [0.02050015 0.22317892]\n",
                        "   [0.99693716 0.35757452]\n",
                        "   [0.9771535  0.3292897 ]\n",
                        "   [0.7964192  0.833084  ]\n",
                        "   [0.60314333 0.6262942 ]\n",
                        "   [0.6594949  0.43910083]\n",
                        "   [0.6853962  0.7627527 ]]]], shape=(4, 1, 20, 2), dtype=float32)\n",
                        "tf.Tensor([0 1 0 1], shape=(4,), dtype=int32)\n"
                    ]
                }
            ],
            "source": [
                "# Concat\n",
                "logits_concat, labels_concat = sequential_concat(data_timeslice, label_timeslice, duration=duration)\n",
                "print(logits_concat) # (batch, (duration - order_sprt), order_sprt + 1, nb_cls)\n",
                "print(labels_concat) # (batch, )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# binary_sprt_confmx "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [],
            "source": [
                "al = 3e-2\n",
                "be = 3e-2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calc thresholds\n",
                "thresh = [np.log(be/(1-al)), np.log((1-be)/al)]\n",
                "if not ( (thresh[1] >= thresh[0]) and (thresh[1] * thresh[0] < 0) ):\n",
                "    raise ValueError(\"thresh must be thresh[1] >= thresh[0] and thresh[1] * thresh[0] < 0. Now thresh = {}\".format(thresh))\n",
                "\n",
                "# Calc log-likelihood ratios\n",
                "dict_llrs = _sequentially_calc_binary_llrs(logits_concat)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[-3.4760986898352733, 3.4760986898352733]"
                        ]
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "thresh"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'llr_019th_order_frame001': <tf.Tensor: id=3020, shape=(4,), dtype=float32, numpy=array([ 0.35210687, -0.06168589, -0.883421  , -0.19616163], dtype=float32)>,\n",
                            " 'llr_019th_order_frame002': <tf.Tensor: id=3029, shape=(4,), dtype=float32, numpy=array([-0.00102802, -0.01670557,  0.07032281,  0.38635477], dtype=float32)>,\n",
                            " 'llr_019th_order_frame003': <tf.Tensor: id=3038, shape=(4,), dtype=float32, numpy=array([-0.10662827,  0.09451175, -0.0805136 , -0.19959724], dtype=float32)>,\n",
                            " 'llr_019th_order_frame004': <tf.Tensor: id=3047, shape=(4,), dtype=float32, numpy=array([-0.46778244, -0.4999634 , -0.4373281 , -0.43428487], dtype=float32)>,\n",
                            " 'llr_019th_order_frame005': <tf.Tensor: id=3056, shape=(4,), dtype=float32, numpy=array([-0.4314655 ,  0.6735593 , -0.33924285,  0.3339158 ], dtype=float32)>,\n",
                            " 'llr_019th_order_frame006': <tf.Tensor: id=3065, shape=(4,), dtype=float32, numpy=array([-0.8547578 , -0.09438752, -0.41665122, -0.44763365], dtype=float32)>,\n",
                            " 'llr_019th_order_frame007': <tf.Tensor: id=3074, shape=(4,), dtype=float32, numpy=array([ 0.00818676,  0.28344998, -0.20653582,  0.0439263 ], dtype=float32)>,\n",
                            " 'llr_019th_order_frame008': <tf.Tensor: id=3083, shape=(4,), dtype=float32, numpy=array([ 0.28273463, -0.42846733,  0.1678553 ,  0.00260746], dtype=float32)>,\n",
                            " 'llr_019th_order_frame009': <tf.Tensor: id=3092, shape=(4,), dtype=float32, numpy=array([ 0.46519393, -0.3443812 ,  0.41484302,  0.00347662], dtype=float32)>,\n",
                            " 'llr_019th_order_frame010': <tf.Tensor: id=3101, shape=(4,), dtype=float32, numpy=array([ 0.30030608, -0.3940266 , -0.20124471, -0.13601655], dtype=float32)>,\n",
                            " 'llr_019th_order_frame011': <tf.Tensor: id=3110, shape=(4,), dtype=float32, numpy=array([-0.61716396,  0.06782192, -0.6475719 ,  0.164688  ], dtype=float32)>,\n",
                            " 'llr_019th_order_frame012': <tf.Tensor: id=3119, shape=(4,), dtype=float32, numpy=array([ 0.2007553 , -0.17540091, -0.33467212, -0.75844795], dtype=float32)>,\n",
                            " 'llr_019th_order_frame013': <tf.Tensor: id=3128, shape=(4,), dtype=float32, numpy=array([-0.03628165,  0.80817354, -0.47003824,  0.6748061 ], dtype=float32)>,\n",
                            " 'llr_019th_order_frame014': <tf.Tensor: id=3137, shape=(4,), dtype=float32, numpy=array([ 0.4135395 , -0.8563343 ,  0.36377722,  0.20267877], dtype=float32)>,\n",
                            " 'llr_019th_order_frame015': <tf.Tensor: id=3146, shape=(4,), dtype=float32, numpy=array([ 0.73159564,  0.602854  ,  0.5114194 , -0.63936263], dtype=float32)>,\n",
                            " 'llr_019th_order_frame016': <tf.Tensor: id=3155, shape=(4,), dtype=float32, numpy=array([-0.10794064, -0.23644769, -0.11538327, -0.64786375], dtype=float32)>,\n",
                            " 'llr_019th_order_frame017': <tf.Tensor: id=3164, shape=(4,), dtype=float32, numpy=array([ 0.18306369, -0.12981302, -0.11508918,  0.03666478], dtype=float32)>,\n",
                            " 'llr_019th_order_frame018': <tf.Tensor: id=3173, shape=(4,), dtype=float32, numpy=array([ 0.5166367 ,  0.7752876 , -0.29310313,  0.02315086], dtype=float32)>,\n",
                            " 'llr_019th_order_frame019': <tf.Tensor: id=3182, shape=(4,), dtype=float32, numpy=array([ 0.26817006, -0.8755165 ,  0.09975767, -0.22039405], dtype=float32)>,\n",
                            " 'llr_019th_order_frame020': <tf.Tensor: id=3191, shape=(4,), dtype=float32, numpy=array([0.1502485 , 0.65212184, 0.15529734, 0.07735652], dtype=float32)>}"
                        ]
                    },
                    "execution_count": 53,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dict_llrs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [],
            "source": [
                "list_preds = []\n",
                "list_hittimes = []\n",
                "list_optout = [] ######################\n",
                "\n",
                "logits_concat_shape = logits_concat.shape\n",
                "order_sprt = int(logits_concat_shape[2] - 1)\n",
                "duration = int(logits_concat_shape[1] + order_sprt)\n",
                "batch_size = labels_concat.shape[0]\n",
                "\n",
                "# Truncated Sequential Probability Ratio Test\n",
                "for iter_batch in range(batch_size):\n",
                "    for iter_frame in range(duration):\n",
                "        # Get log-likelihood ratios\n",
                "        if order_sprt == 0:\n",
                "            key = \"llr_{}th_order_frame{:03d}\".format(\"000\", iter_frame+1)\n",
                "        else:\n",
                "            key = \"llr_{:03d}th_order_frame{:03d}\".format(order_sprt, iter_frame+1)\n",
                "\n",
                "        llr = dict_llrs[key][iter_batch] # scalar\n",
                "\n",
                "        # Decision: reject null hypothesis (classified to class 1)\n",
                "        if llr > thresh[1]:\n",
                "            # Prediction\n",
                "            list_preds.append(tf.constant(1, dtype=tf.int32))\n",
                "            # Hitting time\n",
                "            list_hittimes.append(iter_frame+1)\n",
                "            break\n",
                "\n",
                "        # Decision: accept null hypothesis (classified to class 0)\n",
                "        elif llr < thresh[0]:\n",
                "            # Prediction\n",
                "            list_preds.append(tf.constant(0, dtype=tf.int32))\n",
                "            # Hitting time\n",
                "            list_hittimes.append(iter_frame+1)\n",
                "            break\n",
                "\n",
                "        # Truncate and add to optout list\n",
                "        elif iter_frame == duration - 1:\n",
                "            # Prediction\n",
                "            pred = tf.cast(tf.round(tf.nn.sigmoid(llr)), tf.int32)\n",
                "            list_preds.append(pred)\n",
                "            # Hitting time\n",
                "            list_hittimes.append(iter_frame+1)\n",
                "            # Add to optout list\n",
                "            list_optout.append(iter_batch)\n",
                "                \n",
                "        # Hold\n",
                "        else:\n",
                "            continue"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion matrix\n",
                "confmx = tf.math.confusion_matrix(labels=labels_concat, predictions=list_preds, num_classes=2, dtype=tf.int32)\n",
                "# Mean hitting time\n",
                "mean_hittime = tf.reduce_mean(list_hittimes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<tf.Tensor: id=3871, shape=(2, 2), dtype=int32, numpy=\n",
                            "array([[0, 2],\n",
                            "       [0, 2]], dtype=int32)>"
                        ]
                    },
                    "execution_count": 56,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "confmx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<tf.Tensor: id=3878, shape=(), dtype=int32, numpy=20>"
                        ]
                    },
                    "execution_count": 57,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mean_hittime"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[0, 1, 2, 3]"
                        ]
                    },
                    "execution_count": 58,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "list_optout"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def binary_truncated_sprt_confmx_with_hittime(logits_concat, labels_concat, alpha, beta):\n",
                "    \"\"\"Calculate the confusion matrix and the mean hitting time of the truncated Sequential Probability Ratio Test.\n",
                "    Args:\n",
                "        logits_concat: A logit Tensor with shape (batch, (duration - order_sprt), order_sprt + 1, 2). This is the output of utils.data_processing.sequential_concat(logit_slice, labels_slice).\n",
                "        labels_concat: A non-one-hot label Tensor with shape (batch,). This is the output of utils.data_processing.sequential_conclogit_slice, labels_slice).\n",
                "        alpha: A float number. This is the user-defined false positive rate to be used to calculate thresholds. Note that class 1 is defined as the true class.\n",
                "        beta: A float number. This is the user-defined false negative rate to be used to calculate thresholds. Note that class 1 is defined as the true class.\n",
                "    Returns:\n",
                "        confmx: A confusion matrix Tensor with shape (2, 2).\n",
                "        mean_hittime: A Tensor. The mean hitting time of a batch.\n",
                "        list_optout: A list of offsets. Those sequences didn't finish decision and thus truncated.\n",
                "    Remark:\n",
                "        - Binary classification (num classes = 2) is assumed.\n",
                "        - According to Wald's theory,\n",
                "            false positive rate (alpha) = 0.01\n",
                "            false negative rate (beta) = 0.01\n",
                "        is achievable under the Wald approximation (ignore overshoots), if\n",
                "            thresh[1] (A) = np.log((1-beta)/alpha)\n",
                "            thresh[0] (B) = np.log(beta/(1-alpha)) .\n",
                "        - For example, \n",
                "            thresh = [-4.59511985013459, 4.59511985013459] for alpha = beta = 1e-2.\n",
                "            thresh = [-23.025850929840455, 23.025850929840455] for alpha = beta = 1e-10\n",
                "    \"\"\"\n",
                "    # Calc thresholds\n",
                "    thresh = [np.log(be/(1-al)), np.log((1-be)/al)]\n",
                "    if not ( (thresh[1] >= thresh[0]) and (thresh[1] * thresh[0] < 0) ):\n",
                "        raise ValueError(\"thresh must be thresh[1] >= thresh[0] and thresh[1] * thresh[0] < 0. Now thresh = {}\".format(thresh))\n",
                "\n",
                "    # Calc log-likelihood ratios\n",
                "    dict_llrs = _sequentially_calc_binary_llrs_v2(logits_concat)\n",
                "    \n",
                "    # Truncated Sequential Probability Ratio Test\n",
                "    list_preds = []\n",
                "    list_hittimes = []\n",
                "    list_optout = []\n",
                "\n",
                "    logits_concat_shape = logits_concat.shape\n",
                "    order_sprt = int(logits_concat_shape[2] - 1)\n",
                "    duration = int(logits_concat_shape[1] + order_sprt)\n",
                "    batch_size = labels_concat.shape[0]\n",
                "\n",
                "    for iter_batch in range(batch_size):\n",
                "        for iter_frame in range(duration):\n",
                "            # Get log-likelihood ratios\n",
                "            if order_sprt == 0:\n",
                "                key = \"llr_{}th_order_frame{:03d}\".format(\"000\", iter_frame+1)\n",
                "            else:\n",
                "                key = \"llr_{:03d}th_order_frame{:03d}\".format(order_sprt, iter_frame+1)\n",
                "\n",
                "            llr = dict_llrs[key][iter_batch] # scalar\n",
                "\n",
                "            # Decision: reject null hypothesis (classified to class 1)\n",
                "            if llr > thresh[1]:\n",
                "                # Prediction\n",
                "                list_preds.append(tf.constant(1, dtype=tf.int32))\n",
                "                # Hitting time\n",
                "                list_hittimes.append(iter_frame+1)\n",
                "                break\n",
                "\n",
                "            # Decision: accept null hypothesis (classified to class 0)\n",
                "            elif llr < thresh[0]:\n",
                "                # Prediction\n",
                "                list_preds.append(tf.constant(0, dtype=tf.int32))\n",
                "                # Hitting time\n",
                "                list_hittimes.append(iter_frame+1)\n",
                "                break\n",
                "\n",
                "            # Truncate and add to optout list\n",
                "            elif iter_frame == duration - 1:\n",
                "                # Prediction\n",
                "                pred = tf.cast(tf.round(tf.nn.sigmoid(llr)), tf.int32)\n",
                "                list_preds.append(pred)\n",
                "                # Hitting time\n",
                "                list_hittimes.append(iter_frame+1)\n",
                "                # Add to optout list\n",
                "                list_optout.append(iter_batch)\n",
                "\n",
                "            # Hold\n",
                "            else:\n",
                "                continue\n",
                "    \n",
                "    # Confusion matrix\n",
                "    confmx = tf.math.confusion_matrix(labels=labels_concat, predictions=list_preds, num_classes=2, dtype=tf.int32)\n",
                "    # Mean hitting time\n",
                "    mean_hittime = tf.reduce_mean(list_hittimes)\n",
                "    \n",
                "    return confmx, mean_hittime, list_optout"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# retry, optout_SPRT"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.5.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}