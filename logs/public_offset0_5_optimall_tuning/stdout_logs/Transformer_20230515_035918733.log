2023-05-15 03:59:18.762 | INFO     | utils.misc:fix_random_seed:405 - Random seed is not fixed.
2023-05-15 03:59:18.773 | INFO     | models.temporal_integrators:summarize:566 - 
:'######::'########::'########::'########::::::::::::::::::::::
'##... ##: ##.... ##: ##.... ##:... ##..:::::::::::::::::::::::
 ##:::..:: ##:::: ##: ##:::: ##:::: ##:::::::::::::::::::::::::
. ######:: ########:: ########::::: ##::::'#######:::::::::::::
:..... ##: ##.....::: ##.. ##:::::: ##::::........:::::::::::::
'##::: ##: ##:::::::: ##::. ##::::: ##:::::::::::::::::::::::::
. ######:: ##:::::::: ##:::. ##:::: ##:::::::::::::::::::::::::
:......:::..:::::::::..:::::..:::::..::::::::::::::::::::::::::
'########::::'###::::'##::: ##:'########::'########:'##::::'##:
... ##..::::'## ##::: ###:: ##: ##.... ##: ##.....:: ###::'###:
::: ##:::::'##:. ##:: ####: ##: ##:::: ##: ##::::::: ####'####:
::: ##::::'##:::. ##: ## ## ##: ##:::: ##: ######::: ## ### ##:
::: ##:::: #########: ##. ####: ##:::: ##: ##...:::: ##. #: ##:
::: ##:::: ##.... ##: ##:. ###: ##:::: ##: ##::::::: ##:.:: ##:
::: ##:::: ##:::: ##: ##::. ##: ########:: ########: ##:::: ##:
:::..:::::..:::::..::..::::..::........:::........::..:::::..::

2023-05-15 03:59:18.774 | INFO     | models.temporal_integrators:summarize:569 - [34mofficial PyTorch implementation.[0m
2023-05-15 03:59:20.542 | ERROR    | __main__:objective:48 - An error has been caught in function 'objective', process 'MainProcess' (87549), thread 'MainThread' (140145481953280):
Traceback (most recent call last):

  File "/home/afe/.local/lib/python3.10/site-packages/torchinfo/torchinfo.py", line 288, in forward_pass
    _ = model.to(device)(*x, **kwargs)
        â”‚     â”‚  â”‚        â”‚    â”” {}
        â”‚     â”‚  â”‚        â”” [tensor([[[8.4567e-01, 5.0367e-01, 2.0018e-01,  ..., 8.7267e-01,
        â”‚     â”‚  â”‚                    8.5952e-01, 6.0030e-01],
        â”‚     â”‚  â”‚                   [1.9005e-01, 4.0...
        â”‚     â”‚  â”” device(type='cuda')
        â”‚     â”” <function Module.to at 0x7f7594134940>
        â”” TANDEMformer(
            (dropout): Dropout(p=0.4, inplace=False)
            (pos_encoder): PositionalEncoding(
              (dropout): Dropout(p=0.4, i...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
             â”‚             â”‚       â”” {}
             â”‚             â”” (tensor([[[8.4567e-01, 5.0367e-01, 2.0018e-01,  ..., 8.7267e-01,
             â”‚                         8.5952e-01, 6.0030e-01],
             â”‚                        [1.9005e-01, 4.0...
             â”” <bound method TANDEMformer.forward of TANDEMformer(
                 (dropout): Dropout(p=0.4, inplace=False)
                 (pos_encoder): PositionalEnc...

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/models/temporal_integrators.py", line 762, in forward
    return self.features_to_final_scores(outputs, eff_time_steps)
           â”‚    â”‚                        â”‚        â”” 2
           â”‚    â”‚                        â”” tensor([[[ 0.0595,  0.4680, -0.1407,  ..., -0.1616,  0.0608,  0.1315],
           â”‚    â”‚                                   [-0.5026,  0.4046, -0.7648,  ..., -0.4828, -0...
           â”‚    â”” <function BaseTANDEM.features_to_final_scores at 0x7f74732a6ef0>
           â”” TANDEMformer(
               (dropout): Dropout(p=0.4, inplace=False)
               (pos_encoder): PositionalEncoding(
                 (dropout): Dropout(p=0.4, i...

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/models/temporal_integrators.py", line 560, in features_to_final_scores
    scores_full = self.distance_between_llrs_and_thresholds(llrs, thresh)
                  â”‚    â”‚                                    â”‚     â”” tensor([[[[[0.0000e+00, 2.6494e-05, 2.6494e-05],
                  â”‚    â”‚                                    â”‚                  [2.6494e-05, 0.0000e+00, 2.6494e-05],
                  â”‚    â”‚                                    â”‚                  [2.6494e-05, 2.6...
                  â”‚    â”‚                                    â”” tensor([[[[ 0.0000, -0.1680, -0.0375],
                  â”‚    â”‚                                                [ 0.1680,  0.0000,  0.1305],
                  â”‚    â”‚                                                [ 0.0375, -0.1305,  0.0000]],
                  â”‚    â”‚                                      
                  â”‚    â”‚                                            ...
                  â”‚    â”” <function BaseTANDEM.distance_between_llrs_and_thresholds at 0x7f74732a6e60>
                  â”” TANDEMformer(
                      (dropout): Dropout(p=0.4, inplace=False)
                      (pos_encoder): PositionalEncoding(
                        (dropout): Dropout(p=0.4, i...

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/models/temporal_integrators.py", line 544, in distance_between_llrs_and_thresholds
    scores_full = calc_scores(llrs, thresh)
                  â”‚           â”‚     â”” tensor([[[[[0.0000e+00, 2.6494e-05, 2.6494e-05],
                  â”‚           â”‚                  [2.6494e-05, 0.0000e+00, 2.6494e-05],
                  â”‚           â”‚                  [2.6494e-05, 2.6...
                  â”‚           â”” tensor([[[[ 0.0000, -0.1680, -0.0375],
                  â”‚                       [ 0.1680,  0.0000,  0.1305],
                  â”‚                       [ 0.0375, -0.1305,  0.0000]],
                  â”‚             
                  â”‚                   ...
                  â”” <function calc_scores at 0x7f74732a5ea0>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/models/losses.py", line 143, in calc_scores
    scores_full = llr_mtx - thresh
                  â”‚         â”” tensor([[[[[0.0000e+00, 2.6494e-05, 2.6494e-05],
                  â”‚                      [2.6494e-05, 0.0000e+00, 2.6494e-05],
                  â”‚                      [2.6494e-05, 2.6...
                  â”” tensor([[[[[ 0.0000, -0.1680, -0.0375],
                               [ 0.1680,  0.0000,  0.1305],
                               [ 0.0375, -0.1305,  0.0000]],
                    
                       ...

RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/sprt_tandem_main.py", line 92, in <module>
    main()
    â”” <function main at 0x7f74732a7f40>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/sprt_tandem_main.py", line 86, in main
    run_optuna(objective, device, config_orig)
    â”‚          â”‚          â”‚       â”” {'VERBOSE': True, 'CONFIG_PATH': '/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/config/config_definition.py', 'IS_SEED': False...
    â”‚          â”‚          â”” device(type='cuda')
    â”‚          â”” <function objective at 0x7f76299bfd90>
    â”” <function run_optuna at 0x7f747322d750>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/utils/hyperparameter_tuning.py", line 334, in run_optuna
    else start_optimization(objective, conf)
         â”‚                  â”‚          â”” <utils.misc.ConfigSubset object at 0x7f74732c6740>
         â”‚                  â”” <function objective at 0x7f76299bfd90>
         â”” <function run_optuna.<locals>.start_optimization at 0x7f74732b4160>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/utils/hyperparameter_tuning.py", line 208, in start_optimization
    study.optimize(
    â”‚     â”” <function Study.optimize at 0x7f755bb89a20>
    â”” <optuna.study.study.Study object at 0x7f7467c082b0>

  File "/usr/local/lib/python3.10/dist-packages/optuna/study/study.py", line 425, in optimize
    _optimize(
    â”” <function _optimize at 0x7f755bd67a30>
  File "/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py", line 66, in _optimize
    _optimize_sequential(
    â”” <function _optimize_sequential at 0x7f755bb891b0>
  File "/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py", line 163, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   â”‚          â”‚      â”‚     â”” ()
                   â”‚          â”‚      â”” <function run_optuna.<locals>.start_optimization.<locals>.<lambda> at 0x7f7467c4c310>
                   â”‚          â”” <optuna.study.study.Study object at 0x7f7467c082b0>
                   â”” <function _run_trial at 0x7f755bb89240>
  File "/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
                      â”‚    â”” <optuna.trial._trial.Trial object at 0x7f7467b0fca0>
                      â”” <function run_optuna.<locals>.start_optimization.<locals>.<lambda> at 0x7f7467c4c310>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/utils/hyperparameter_tuning.py", line 209, in <lambda>
    lambda trial: objective(trial, device, config),
           â”‚      â”‚         â”‚      â”‚       â”” {'VERBOSE': True, 'CONFIG_PATH': '/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/config/config_definition.py', 'IS_SEED': False...
           â”‚      â”‚         â”‚      â”” device(type='cuda')
           â”‚      â”‚         â”” <optuna.trial._trial.Trial object at 0x7f7467b0fca0>
           â”‚      â”” <function objective at 0x7f76299bfd90>
           â”” <optuna.trial._trial.Trial object at 0x7f7467b0fca0>

> File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/sprt_tandem_main.py", line 48, in objective
    model, optimizer, data_loaders, tb_writer = prepare_for_training(config, device)
                                                â”‚                    â”‚       â”” device(type='cuda')
                                                â”‚                    â”” {'VERBOSE': True, 'CONFIG_PATH': '/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/config/config_definition.py', 'IS_SEED': False...
                                                â”” <function prepare_for_training at 0x7f74732a7520>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/utils/training.py", line 67, in prepare_for_training
    model = import_model(config, device, tb_writer=None)
            â”‚            â”‚       â”” device(type='cuda')
            â”‚            â”” {'VERBOSE': True, 'CONFIG_PATH': '/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/config/config_definition.py', 'IS_SEED': False...
            â”” <function import_model at 0x7f747322fa30>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/models/temporal_integrators.py", line 54, in import_model
    model.summarize(tb_writer, device)
    â”‚     â”‚         â”‚          â”” device(type='cuda')
    â”‚     â”‚         â”” None
    â”‚     â”” <function BaseTANDEM.summarize at 0x7f74732a6f80>
    â”” TANDEMformer(
        (dropout): Dropout(p=0.4, inplace=False)
        (pos_encoder): PositionalEncoding(
          (dropout): Dropout(p=0.4, i...

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/models/temporal_integrators.py", line 580, in summarize
    sum_str = str(summary(self, example_input.shape, device=device, verbose=0))
                  â”‚       â”‚     â”‚             â”‚             â”” device(type='cuda')
                  â”‚       â”‚     â”‚             â”” <attribute 'shape' of 'torch._C._TensorBase' objects>
                  â”‚       â”‚     â”” tensor([[[ 6.8892e-02, -1.4186e-01,  4.4148e-01,  ...,  1.6179e+00,
                  â”‚       â”‚                  2.2258e-01, -1.1983e-01],
                  â”‚       â”‚                [ 4.8983e-0...
                  â”‚       â”” TANDEMformer(
                  â”‚           (dropout): Dropout(p=0.4, inplace=False)
                  â”‚           (pos_encoder): PositionalEncoding(
                  â”‚             (dropout): Dropout(p=0.4, i...
                  â”” <function summary at 0x7f74732937f0>

  File "/home/afe/.local/lib/python3.10/site-packages/torchinfo/torchinfo.py", line 218, in summary
    summary_list = forward_pass(
                   â”” <function forward_pass at 0x7f74732a52d0>
  File "/home/afe/.local/lib/python3.10/site-packages/torchinfo/torchinfo.py", line 297, in forward_pass
    raise RuntimeError(

RuntimeError: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [TransformerEncoder: 1, TransformerEncoderLayer: 3, Linear: 1, Dropout: 1, TransformerEncoder: 1, TransformerEncoderLayer: 3, Linear: 1, Dropout: 1, GELU: 1, Linear: 1, GELU: 1, Linear: 1]
2023-05-15 03:59:20.784 | INFO     | utils.logging:investigate_log:155 - num_warning=0/num_error=1 in the .log file.
2023-05-15 03:59:20.784 | WARNING  | utils.logging:investigate_log:161 - Found ERROR! check the .log file for debug!
2023-05-15 03:59:20.810 | WARNING  | optuna.study._optimize:_log_failed_trial:261 - Trial 33 failed with parameters: {'LIST_IS_POSITIONAL_ENCODING': False, 'LIST_MODEL_BACKBONE': 'Transformer', 'LIST_WEIGHT_DECAY': 0.0, 'LIST_LEARNING_RATE': 8.781500326182534e-05, 'LIST_LLLR_VERSION': 'LLLR', 'LIST_ACTIVATION_FC': 'gelu', 'LIST_PARAM_MULTIPLET_LOSS': 0.8, 'LIST_PARAM_LLR_LOSS': 0.1, 'LIST_IS_ADAPTIVE_LOSS': True, 'LIST_ORDER_SPRT': 1, 'LIST_OPTIMIZER': 'adam', 'LIST_IS_NORMALIZE': False, 'LIST_NUM_THRESH': 1500, 'LIST_SPARSITY': 'linspace', 'LIST_NUM_BLOCKS': 1, 'LIST_NUM_HEADS': 4, 'LIST_DROPOUT': 0.4, 'LIST_FF_DIM': 32, 'LIST_MLP_UNITS': 64} because of the following error: TypeError('cannot unpack non-iterable NoneType object').
Traceback (most recent call last):

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/sprt_tandem_main.py", line 92, in <module>
    main()
    â”” <function main at 0x7f74732a7f40>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/sprt_tandem_main.py", line 86, in main
    run_optuna(objective, device, config_orig)
    â”‚          â”‚          â”‚       â”” {'VERBOSE': True, 'CONFIG_PATH': '/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/config/config_definition.py', 'IS_SEED': False...
    â”‚          â”‚          â”” device(type='cuda')
    â”‚          â”” <function objective at 0x7f76299bfd90>
    â”” <function run_optuna at 0x7f747322d750>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/utils/hyperparameter_tuning.py", line 334, in run_optuna
    else start_optimization(objective, conf)
         â”‚                  â”‚          â”” <utils.misc.ConfigSubset object at 0x7f74732c6740>
         â”‚                  â”” <function objective at 0x7f76299bfd90>
         â”” <function run_optuna.<locals>.start_optimization at 0x7f74732b4160>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/utils/hyperparameter_tuning.py", line 208, in start_optimization
    study.optimize(
    â”‚     â”” <function Study.optimize at 0x7f755bb89a20>
    â”” <optuna.study.study.Study object at 0x7f7467c082b0>

  File "/usr/local/lib/python3.10/dist-packages/optuna/study/study.py", line 425, in optimize
    _optimize(
    â”” <function _optimize at 0x7f755bd67a30>
  File "/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py", line 66, in _optimize
    _optimize_sequential(
    â”” <function _optimize_sequential at 0x7f755bb891b0>
  File "/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py", line 163, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   â”‚          â”‚      â”‚     â”” ()
                   â”‚          â”‚      â”” <function run_optuna.<locals>.start_optimization.<locals>.<lambda> at 0x7f7467c4c310>
                   â”‚          â”” <optuna.study.study.Study object at 0x7f7467c082b0>
                   â”” <function _run_trial at 0x7f755bb89240>
> File "/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py", line 200, in _run_trial
    value_or_values = func(trial)
                      â”‚    â”” <optuna.trial._trial.Trial object at 0x7f7467b0fca0>
                      â”” <function run_optuna.<locals>.start_optimization.<locals>.<lambda> at 0x7f7467c4c310>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/utils/hyperparameter_tuning.py", line 209, in <lambda>
    lambda trial: objective(trial, device, config),
           â”‚      â”‚         â”‚      â”‚       â”” {'VERBOSE': True, 'CONFIG_PATH': '/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/config/config_definition.py', 'IS_SEED': False...
           â”‚      â”‚         â”‚      â”” device(type='cuda')
           â”‚      â”‚         â”” <optuna.trial._trial.Trial object at 0x7f7467b0fca0>
           â”‚      â”” <function objective at 0x7f76299bfd90>
           â”” <optuna.trial._trial.Trial object at 0x7f7467b0fca0>

  File "/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/sprt_tandem_main.py", line 48, in objective
    model, optimizer, data_loaders, tb_writer = prepare_for_training(config, device)
                                                â”‚                    â”‚       â”” device(type='cuda')
                                                â”‚                    â”” {'VERBOSE': True, 'CONFIG_PATH': '/home/afe/Dropbox/GitHub/SPRT-TANDEM-PyTorch/config/config_definition.py', 'IS_SEED': False...
                                                â”” <function prepare_for_training at 0x7f74732a7520>

TypeError: cannot unpack non-iterable NoneType object
2023-05-15 03:59:20.815 | WARNING  | optuna.study._optimize:_log_failed_trial:268 - Trial 33 failed with value None.
2023-05-15 03:59:20.830 | INFO     | utils.misc:__exit__:207 - elapsed time:  0.000832 hours. ()
2023-05-15 03:59:20.831 | INFO     | utils.misc:__exit__:208 - Memory usage: 13.55 megabytes
