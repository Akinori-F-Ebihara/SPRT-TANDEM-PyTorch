2023-05-02 07:31:05.621 | INFO     | utils.misc:fix_random_seed:405 - Random seed is not fixed.
2023-05-02 07:31:05.632 | INFO     | models.temporal_integrators:summarize:568 - 
:'######::'########::'########::'########::::::::::::::::::::::
'##... ##: ##.... ##: ##.... ##:... ##..:::::::::::::::::::::::
 ##:::..:: ##:::: ##: ##:::: ##:::: ##:::::::::::::::::::::::::
. ######:: ########:: ########::::: ##::::'#######:::::::::::::
:..... ##: ##.....::: ##.. ##:::::: ##::::........:::::::::::::
'##::: ##: ##:::::::: ##::. ##::::: ##:::::::::::::::::::::::::
. ######:: ##:::::::: ##:::. ##:::: ##:::::::::::::::::::::::::
:......:::..:::::::::..:::::..:::::..::::::::::::::::::::::::::
'########::::'###::::'##::: ##:'########::'########:'##::::'##:
... ##..::::'## ##::: ###:: ##: ##.... ##: ##.....:: ###::'###:
::: ##:::::'##:. ##:: ####: ##: ##:::: ##: ##::::::: ####'####:
::: ##::::'##:::. ##: ## ## ##: ##:::: ##: ######::: ## ### ##:
::: ##:::: #########: ##. ####: ##:::: ##: ##...:::: ##. #: ##:
::: ##:::: ##.... ##: ##:. ###: ##:::: ##: ##::::::: ##:.:: ##:
::: ##:::: ##:::: ##: ##::. ##: ########:: ########: ##:::: ##:
:::..:::::..:::::..::..::::..::........:::........::..:::::..::

2023-05-02 07:31:05.633 | INFO     | models.temporal_integrators:summarize:571 - [34mofficial PyTorch implementation.[0m
2023-05-02 07:31:06.949 | INFO     | models.temporal_integrators:summarize:593 - Network summary:
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
TANDEMformer                                  [150, 50, 3, 3]           259
â”œâ”€TransformerEncoder: 1-1                     [7350, 1, 128]            --
â”‚    â””â”€ModuleList: 2-2                        --                        (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-1      [7350, 1, 128]            74,912
â”œâ”€Linear: 1-2                                 [7350, 64]                8,256
â”œâ”€Dropout: 1-3                                [7350, 64]                --
â”œâ”€TransformerEncoder: 1-4                     [7350, 2, 128]            (recursive)
â”‚    â””â”€ModuleList: 2-2                        --                        (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-2      [7350, 2, 128]            (recursive)
â”œâ”€Linear: 1-5                                 [7350, 64]                (recursive)
â”œâ”€Dropout: 1-6                                [7350, 64]                --
â”œâ”€GELU: 1-7                                   [7350, 64]                --
â”œâ”€Linear: 1-8                                 [7350, 3]                 195
â”œâ”€GELU: 1-9                                   [7350, 64]                --
â”œâ”€Linear: 1-10                                [7350, 3]                 (recursive)
===============================================================================================
Total params: 83,622
Trainable params: 83,622
Non-trainable params: 0
Total mult-adds (M): 124.23
===============================================================================================
Input size (MB): 3.84
Forward/backward pass size (MB): 7.88
Params size (MB): 0.03
Estimated Total Size (MB): 11.75
===============================================================================================
2023-05-02 07:31:06.950 | INFO     | models.temporal_integrators:summarize:594 - Example input shape: torch.Size([150, 50, 128])
2023-05-02 07:31:06.950 | INFO     | models.temporal_integrators:summarize:595 - Example output shape: torch.Size([150, 50, 3, 3])
2023-05-02 07:31:06.952 | INFO     | models.temporal_integrators:import_model:58 - model moved onto: [33mcpu.[0m
2023-05-02 07:31:06.952 | INFO     | models.optimizers:initialize_optimizer:44 - Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 8.65251579982199e-05
    maximize: False
    weight_decay: 0.001
)
2023-05-02 07:31:06.952 | INFO     | datasets.data_processing:lmdb_dataloaders:293 - loading data... 
2023-05-02 07:31:06.953 | INFO     | datasets.data_processing:lmdb_dataloaders:295 - If this process takes long, consider setting is_load_onto_memory=False or use LMDBIterableDataset.
2023-05-02 07:31:09.323 | INFO     | __main__:objective:357 - Starting epoch #0.
