2023-05-01 05:00:12.962 | INFO     | utils.misc:fix_random_seed:405 - Random seed is not fixed.
2023-05-01 05:00:12.987 | INFO     | models.temporal_integrators:summarize:568 - 
:'######::'########::'########::'########::::::::::::::::::::::
'##... ##: ##.... ##: ##.... ##:... ##..:::::::::::::::::::::::
 ##:::..:: ##:::: ##: ##:::: ##:::: ##:::::::::::::::::::::::::
. ######:: ########:: ########::::: ##::::'#######:::::::::::::
:..... ##: ##.....::: ##.. ##:::::: ##::::........:::::::::::::
'##::: ##: ##:::::::: ##::. ##::::: ##:::::::::::::::::::::::::
. ######:: ##:::::::: ##:::. ##:::: ##:::::::::::::::::::::::::
:......:::..:::::::::..:::::..:::::..::::::::::::::::::::::::::
'########::::'###::::'##::: ##:'########::'########:'##::::'##:
... ##..::::'## ##::: ###:: ##: ##.... ##: ##.....:: ###::'###:
::: ##:::::'##:. ##:: ####: ##: ##:::: ##: ##::::::: ####'####:
::: ##::::'##:::. ##: ## ## ##: ##:::: ##: ######::: ## ### ##:
::: ##:::: #########: ##. ####: ##:::: ##: ##...:::: ##. #: ##:
::: ##:::: ##.... ##: ##:. ###: ##:::: ##: ##::::::: ##:.:: ##:
::: ##:::: ##:::: ##: ##::. ##: ########:: ########: ##:::: ##:
:::..:::::..:::::..::..::::..::........:::........::..:::::..::

2023-05-01 05:00:12.988 | INFO     | models.temporal_integrators:summarize:571 - [34mofficial PyTorch implementation.[0m
2023-05-01 05:00:13.131 | INFO     | models.temporal_integrators:summarize:593 - Network summary:
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
TANDEMformer                                  [150, 50, 3, 3]           771
â”œâ”€TransformerEncoder: 1-1                     [6750, 1, 128]            --
â”‚    â””â”€ModuleList: 2-6                        --                        (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-1      [6750, 1, 128]            83,136
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-2      [6750, 1, 128]            83,136
â”œâ”€Linear: 1-2                                 [6750, 64]                8,256
â”œâ”€Dropout: 1-3                                [6750, 64]                --
â”œâ”€TransformerEncoder: 1-4                     [6750, 2, 128]            (recursive)
â”‚    â””â”€ModuleList: 2-6                        --                        (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-3      [6750, 2, 128]            (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-4      [6750, 2, 128]            (recursive)
â”œâ”€Linear: 1-5                                 [6750, 64]                (recursive)
â”œâ”€Dropout: 1-6                                [6750, 64]                --
â”œâ”€TransformerEncoder: 1-7                     [6750, 3, 128]            (recursive)
â”‚    â””â”€ModuleList: 2-6                        --                        (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-5      [6750, 3, 128]            (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-6      [6750, 3, 128]            (recursive)
â”œâ”€Linear: 1-8                                 [6750, 64]                (recursive)
â”œâ”€Dropout: 1-9                                [6750, 64]                --
â”œâ”€TransformerEncoder: 1-10                    [6750, 4, 128]            (recursive)
â”‚    â””â”€ModuleList: 2-6                        --                        (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-7      [6750, 4, 128]            (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-8      [6750, 4, 128]            (recursive)
â”œâ”€Linear: 1-11                                [6750, 64]                (recursive)
â”œâ”€Dropout: 1-12                               [6750, 64]                --
â”œâ”€TransformerEncoder: 1-13                    [6750, 5, 128]            (recursive)
â”‚    â””â”€ModuleList: 2-6                        --                        (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-9      [6750, 5, 128]            (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-10     [6750, 5, 128]            (recursive)
â”œâ”€Linear: 1-14                                [6750, 64]                (recursive)
â”œâ”€Dropout: 1-15                               [6750, 64]                --
â”œâ”€TransformerEncoder: 1-16                    [6750, 6, 128]            (recursive)
â”‚    â””â”€ModuleList: 2-6                        --                        (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-11     [6750, 6, 128]            (recursive)
â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-12     [6750, 6, 128]            (recursive)
â”œâ”€Linear: 1-17                                [6750, 64]                (recursive)
â”œâ”€Dropout: 1-18                               [6750, 64]                --
â”œâ”€Linear: 1-19                                [6750, 3]                 195
â”œâ”€Linear: 1-20                                [6750, 3]                 (recursive)
â”œâ”€Linear: 1-21                                [6750, 3]                 (recursive)
â”œâ”€Linear: 1-22                                [6750, 3]                 (recursive)
â”œâ”€Linear: 1-23                                [6750, 3]                 (recursive)
â”œâ”€Linear: 1-24                                [6750, 3]                 (recursive)
===============================================================================================
Total params: 175,494
Trainable params: 175,494
Non-trainable params: 0
Total mult-adds (G): 1.73
===============================================================================================
Input size (MB): 3.84
Forward/backward pass size (MB): 1037.77
Params size (MB): 0.17
Estimated Total Size (MB): 1041.78
===============================================================================================
2023-05-01 05:00:13.132 | INFO     | models.temporal_integrators:summarize:594 - Example input shape: torch.Size([150, 50, 128])
2023-05-01 05:00:13.132 | INFO     | models.temporal_integrators:summarize:595 - Example output shape: torch.Size([150, 50, 3, 3])
2023-05-01 05:00:13.136 | INFO     | models.temporal_integrators:import_model:58 - model moved onto: [33mcuda.[0m
2023-05-01 05:00:13.137 | INFO     | models.optimizers:initialize_optimizer:44 - Optimizer:
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 6.447232269669382e-05
    maximize: False
    weight_decay: 0.0004
)
2023-05-01 05:00:13.138 | INFO     | datasets.data_processing:lmdb_dataloaders:293 - loading data... 
2023-05-01 05:00:13.138 | INFO     | datasets.data_processing:lmdb_dataloaders:295 - If this process takes long, consider setting is_load_onto_memory=False or use LMDBIterableDataset.
2023-05-01 05:00:15.793 | INFO     | __main__:objective:357 - Starting epoch #0.
2023-05-01 05:00:19.428 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:00:19.429 | INFO     | utils.logging:log_training_results:281 - Global Step =      0
2023-05-01 05:00:19.429 | INFO     | utils.logging:log_training_results:282 - val mean(MacRec)_t: 0.31589335203170776
2023-05-01 05:00:19.430 | INFO     | utils.logging:log_training_results:287 - val mean ABSerr: 3.5015861988067627
2023-05-01 05:00:19.430 | INFO     | utils.logging:log_training_results:290 - val ausat from confmx: 0.3094466030597687
2023-05-01 05:00:19.430 | INFO     | utils.logging:log_training_results:301 - val MCE loss:1.10267 * 1.0 * 0.22572
2023-05-01 05:00:19.431 | INFO     | utils.logging:log_training_results:309 - val LLLR :1.15008 * 0.0 * -0.96871
2023-05-01 05:00:19.431 | INFO     | utils.logging:log_training_results:317 - val weight decay:1867.20471 * 0.0004 * 1.22239
2023-05-01 05:00:21.222 | INFO     | utils.logging:save_sdre_imgs:710 - Figures saved.
2023-05-01 05:00:21.642 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:00:21.643 | INFO     | utils.logging:log_training_results:281 - Global Step =      0
2023-05-01 05:00:21.643 | INFO     | utils.logging:log_training_results:282 - train mean(MacRec)_t: 0.35000935196876526
2023-05-01 05:00:21.644 | INFO     | utils.logging:log_training_results:287 - train mean ABSerr: 3.581465244293213
2023-05-01 05:00:21.644 | INFO     | utils.logging:log_training_results:290 - train ausat from confmx: 0.31899306178092957
2023-05-01 05:00:21.645 | INFO     | utils.logging:log_training_results:301 - train MCE loss:1.10335 * 1.0 * 0.22579
2023-05-01 05:00:21.645 | INFO     | utils.logging:log_training_results:309 - train LLLR :1.32621 * 0.0 * -0.96865
2023-05-01 05:00:21.646 | INFO     | utils.logging:log_training_results:317 - train weight decay:1867.20483 * 0.0004 * 1.22233
2023-05-01 05:00:56.774 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:00:56.775 | INFO     | utils.logging:log_training_results:281 - Global Step =    250
2023-05-01 05:00:56.776 | INFO     | utils.logging:log_training_results:282 - val mean(MacRec)_t: 0.8718932867050171
2023-05-01 05:00:56.776 | INFO     | utils.logging:log_training_results:287 - val mean ABSerr: 0.4284675419330597
2023-05-01 05:00:56.776 | INFO     | utils.logging:log_training_results:290 - val ausat from confmx: 0.9738038182258606
2023-05-01 05:00:56.777 | INFO     | utils.logging:log_training_results:301 - val MCE loss:0.86479 * 1.0 * 0.24030
2023-05-01 05:00:56.777 | INFO     | utils.logging:log_training_results:309 - val LLLR :0.30499 * 0.0 * -0.95254
2023-05-01 05:00:56.778 | INFO     | utils.logging:log_training_results:317 - val weight decay:1826.37268 * 0.0004 * 1.20623
2023-05-01 05:00:57.524 | INFO     | utils.checkpoint:update_and_save_result:168 - [36mBest value updated![0m
2023-05-01 05:00:57.546 | INFO     | utils.checkpoint:save_checkpoint:83 - [36mSaved checkpoint[0m at step 250.
2023-05-01 05:00:58.465 | INFO     | utils.logging:save_sdre_imgs:710 - Figures saved.
2023-05-01 05:00:58.878 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:00:58.879 | INFO     | utils.logging:log_training_results:281 - Global Step =    250
2023-05-01 05:00:58.879 | INFO     | utils.logging:log_training_results:282 - train mean(MacRec)_t: 0.7609966993331909
2023-05-01 05:00:58.879 | INFO     | utils.logging:log_training_results:287 - train mean ABSerr: 1.8573652505874634
2023-05-01 05:00:58.880 | INFO     | utils.logging:log_training_results:290 - train ausat from confmx: 0.8900234699249268
2023-05-01 05:00:58.880 | INFO     | utils.logging:log_training_results:301 - train MCE loss:0.89296 * 1.0 * 0.24036
2023-05-01 05:00:58.881 | INFO     | utils.logging:log_training_results:309 - train LLLR :0.63261 * 0.0 * -0.95247
2023-05-01 05:00:58.881 | INFO     | utils.logging:log_training_results:317 - train weight decay:1826.37256 * 0.0004 * 1.20617
2023-05-01 05:01:18.990 | INFO     | __main__:objective:357 - Starting epoch #1.
2023-05-01 05:01:35.345 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:01:35.346 | INFO     | utils.logging:log_training_results:281 - Global Step =    500
2023-05-01 05:01:35.347 | INFO     | utils.logging:log_training_results:282 - val mean(MacRec)_t: 0.874363362789154
2023-05-01 05:01:35.347 | INFO     | utils.logging:log_training_results:287 - val mean ABSerr: 0.5250887870788574
2023-05-01 05:01:35.348 | INFO     | utils.logging:log_training_results:290 - val ausat from confmx: 0.9763611555099487
2023-05-01 05:01:35.348 | INFO     | utils.logging:log_training_results:301 - val MCE loss:0.86000 * 1.0 * 0.25311
2023-05-01 05:01:35.349 | INFO     | utils.logging:log_training_results:309 - val LLLR :0.30032 * 0.0 * -0.93623
2023-05-01 05:01:35.349 | INFO     | utils.logging:log_training_results:317 - val weight decay:1790.31409 * 0.0004 * 1.18999
2023-05-01 05:01:36.276 | INFO     | utils.checkpoint:update_and_save_result:168 - [36mBest value updated![0m
2023-05-01 05:01:36.299 | INFO     | utils.checkpoint:save_checkpoint:83 - [36mSaved checkpoint[0m at step 500.
2023-05-01 05:01:36.303 | INFO     | utils.checkpoint:keep_max_num_saved_models:101 - Removed the oldest model for max_to_keep=1
2023-05-01 05:01:37.245 | INFO     | utils.logging:save_sdre_imgs:710 - Figures saved.
2023-05-01 05:01:37.651 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:01:37.651 | INFO     | utils.logging:log_training_results:281 - Global Step =    500
2023-05-01 05:01:37.652 | INFO     | utils.logging:log_training_results:282 - train mean(MacRec)_t: 0.7997272610664368
2023-05-01 05:01:37.652 | INFO     | utils.logging:log_training_results:287 - train mean ABSerr: 1.7530590295791626
2023-05-01 05:01:37.653 | INFO     | utils.logging:log_training_results:290 - train ausat from confmx: 0.9243444800376892
2023-05-01 05:01:37.653 | INFO     | utils.logging:log_training_results:301 - train MCE loss:0.90706 * 1.0 * 0.25317
2023-05-01 05:01:37.653 | INFO     | utils.logging:log_training_results:309 - train LLLR :0.57293 * 0.0 * -0.93617
2023-05-01 05:01:37.654 | INFO     | utils.logging:log_training_results:317 - train weight decay:1790.31396 * 0.0004 * 1.18993
2023-05-01 05:02:12.892 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:02:12.893 | INFO     | utils.logging:log_training_results:281 - Global Step =    750
2023-05-01 05:02:12.894 | INFO     | utils.logging:log_training_results:282 - val mean(MacRec)_t: 0.873930037021637
2023-05-01 05:02:12.894 | INFO     | utils.logging:log_training_results:287 - val mean ABSerr: 0.5667940974235535
2023-05-01 05:02:12.895 | INFO     | utils.logging:log_training_results:290 - val ausat from confmx: 0.975877583026886
2023-05-01 05:02:12.896 | INFO     | utils.logging:log_training_results:301 - val MCE loss:0.85957 * 1.0 * 0.26536
2023-05-01 05:02:12.896 | INFO     | utils.logging:log_training_results:309 - val LLLR :0.30161 * 0.0 * -0.91981
2023-05-01 05:02:12.897 | INFO     | utils.logging:log_training_results:317 - val weight decay:1757.55945 * 0.0004 * 1.17369
2023-05-01 05:02:15.141 | INFO     | utils.logging:save_sdre_imgs:710 - Figures saved.
2023-05-01 05:02:15.573 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:02:15.574 | INFO     | utils.logging:log_training_results:281 - Global Step =    750
2023-05-01 05:02:15.574 | INFO     | utils.logging:log_training_results:282 - train mean(MacRec)_t: 0.826464056968689
2023-05-01 05:02:15.575 | INFO     | utils.logging:log_training_results:287 - train mean ABSerr: 1.6437960863113403
2023-05-01 05:02:15.575 | INFO     | utils.logging:log_training_results:290 - train ausat from confmx: 0.9437558650970459
2023-05-01 05:02:15.576 | INFO     | utils.logging:log_training_results:301 - train MCE loss:0.89353 * 1.0 * 0.26540
2023-05-01 05:02:15.576 | INFO     | utils.logging:log_training_results:309 - train LLLR :0.50331 * 0.0 * -0.91975
2023-05-01 05:02:15.576 | INFO     | utils.logging:log_training_results:317 - train weight decay:1757.55933 * 0.0004 * 1.17362
2023-05-01 05:02:22.817 | INFO     | __main__:objective:357 - Starting epoch #2.
2023-05-01 05:02:52.548 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:02:52.551 | INFO     | utils.logging:log_training_results:281 - Global Step =   1000
2023-05-01 05:02:52.552 | INFO     | utils.logging:log_training_results:282 - val mean(MacRec)_t: 0.8740633130073547
2023-05-01 05:02:52.553 | INFO     | utils.logging:log_training_results:287 - val mean ABSerr: 0.6143142580986023
2023-05-01 05:02:52.553 | INFO     | utils.logging:log_training_results:290 - val ausat from confmx: 0.9762768745422363
2023-05-01 05:02:52.554 | INFO     | utils.logging:log_training_results:301 - val MCE loss:0.85941 * 1.0 * 0.27702
2023-05-01 05:02:52.555 | INFO     | utils.logging:log_training_results:309 - val LLLR :0.30252 * 0.0 * -0.90328
2023-05-01 05:02:52.556 | INFO     | utils.logging:log_training_results:317 - val weight decay:1726.15125 * 0.0004 * 1.15731
2023-05-01 05:02:54.355 | INFO     | utils.logging:save_sdre_imgs:710 - Figures saved.
2023-05-01 05:02:54.783 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:02:54.785 | INFO     | utils.logging:log_training_results:281 - Global Step =   1000
2023-05-01 05:02:54.786 | INFO     | utils.logging:log_training_results:282 - train mean(MacRec)_t: 0.8160234689712524
2023-05-01 05:02:54.787 | INFO     | utils.logging:log_training_results:287 - train mean ABSerr: 1.5610183477401733
2023-05-01 05:02:54.788 | INFO     | utils.logging:log_training_results:290 - train ausat from confmx: 0.9323383569717407
2023-05-01 05:02:54.788 | INFO     | utils.logging:log_training_results:301 - train MCE loss:0.87333 * 1.0 * 0.27706
2023-05-01 05:02:54.789 | INFO     | utils.logging:log_training_results:309 - train LLLR :0.50639 * 0.0 * -0.90321
2023-05-01 05:02:54.789 | INFO     | utils.logging:log_training_results:317 - train weight decay:1726.15112 * 0.0004 * 1.15725
2023-05-01 05:03:21.843 | INFO     | __main__:objective:357 - Starting epoch #3.
2023-05-01 05:03:31.972 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:03:31.973 | INFO     | utils.logging:log_training_results:281 - Global Step =   1250
2023-05-01 05:03:31.973 | INFO     | utils.logging:log_training_results:282 - val mean(MacRec)_t: 0.8751332759857178
2023-05-01 05:03:31.974 | INFO     | utils.logging:log_training_results:287 - val mean ABSerr: 0.59279465675354
2023-05-01 05:03:31.974 | INFO     | utils.logging:log_training_results:290 - val ausat from confmx: 0.9762417674064636
2023-05-01 05:03:31.974 | INFO     | utils.logging:log_training_results:301 - val MCE loss:0.85858 * 1.0 * 0.28816
2023-05-01 05:03:31.975 | INFO     | utils.logging:log_training_results:309 - val LLLR :0.29862 * 0.0 * -0.88664
2023-05-01 05:03:31.975 | INFO     | utils.logging:log_training_results:317 - val weight decay:1695.11365 * 0.0004 * 1.14089
2023-05-01 05:03:32.877 | INFO     | utils.checkpoint:update_and_save_result:168 - [36mBest value updated![0m
2023-05-01 05:03:32.902 | INFO     | utils.checkpoint:save_checkpoint:83 - [36mSaved checkpoint[0m at step 1250.
2023-05-01 05:03:32.905 | INFO     | utils.checkpoint:keep_max_num_saved_models:101 - Removed the oldest model for max_to_keep=1
2023-05-01 05:03:33.882 | INFO     | utils.logging:save_sdre_imgs:710 - Figures saved.
2023-05-01 05:03:34.308 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:03:34.309 | INFO     | utils.logging:log_training_results:281 - Global Step =   1250
2023-05-01 05:03:34.309 | INFO     | utils.logging:log_training_results:282 - train mean(MacRec)_t: 0.8246333003044128
2023-05-01 05:03:34.310 | INFO     | utils.logging:log_training_results:287 - train mean ABSerr: 1.5188531875610352
2023-05-01 05:03:34.310 | INFO     | utils.logging:log_training_results:290 - train ausat from confmx: 0.9498423933982849
2023-05-01 05:03:34.311 | INFO     | utils.logging:log_training_results:301 - train MCE loss:0.86676 * 1.0 * 0.28820
2023-05-01 05:03:34.311 | INFO     | utils.logging:log_training_results:309 - train LLLR :0.41283 * 0.0 * -0.88657
2023-05-01 05:03:34.312 | INFO     | utils.logging:log_training_results:317 - train weight decay:1695.11365 * 0.0004 * 1.14082
2023-05-01 05:04:10.403 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:04:10.404 | INFO     | utils.logging:log_training_results:281 - Global Step =   1500
2023-05-01 05:04:10.404 | INFO     | utils.logging:log_training_results:282 - val mean(MacRec)_t: 0.8746265769004822
2023-05-01 05:04:10.405 | INFO     | utils.logging:log_training_results:287 - val mean ABSerr: 0.5937232375144958
2023-05-01 05:04:10.405 | INFO     | utils.logging:log_training_results:290 - val ausat from confmx: 0.9767905473709106
2023-05-01 05:04:10.406 | INFO     | utils.logging:log_training_results:301 - val MCE loss:0.85845 * 1.0 * 0.29889
2023-05-01 05:04:10.406 | INFO     | utils.logging:log_training_results:309 - val LLLR :0.29996 * 0.0 * -0.86990
2023-05-01 05:04:10.407 | INFO     | utils.logging:log_training_results:317 - val weight decay:1664.33435 * 0.0004 * 1.12441
2023-05-01 05:04:12.292 | INFO     | utils.logging:save_sdre_imgs:710 - Figures saved.
2023-05-01 05:04:12.715 | INFO     | utils.logging:log_training_results:280 - 
2023-05-01 05:04:12.715 | INFO     | utils.logging:log_training_results:281 - Global Step =   1500
2023-05-01 05:04:12.716 | INFO     | utils.logging:log_training_results:282 - train mean(MacRec)_t: 0.8306899666786194
2023-05-01 05:04:12.716 | INFO     | utils.logging:log_training_results:287 - train mean ABSerr: 1.5335392951965332
2023-05-01 05:04:12.717 | INFO     | utils.logging:log_training_results:290 - train ausat from confmx: 0.952773928642273
2023-05-01 05:04:12.717 | INFO     | utils.logging:log_training_results:301 - train MCE loss:0.88485 * 1.0 * 0.29893
2023-05-01 05:04:12.718 | INFO     | utils.logging:log_training_results:309 - train LLLR :0.43577 * 0.0 * -0.86984
2023-05-01 05:04:12.718 | INFO     | utils.logging:log_training_results:317 - train weight decay:1664.33423 * 0.0004 * 1.12434
